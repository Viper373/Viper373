https://viper3.top/857/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！实现拉格朗日插值法中。自定义列向量插值函数时，在取值处应使用基于数字索引的iloc方法；在判断元素是否需要插值时，应使用基于自定义索引的loc方法。
# 销量数据路径
inputFile = '../data/catering_sale.xls'
# 输出数据路径
outputFile = '../tmp/sales.xls'
# 读入数据
data = pd.read_excel(inputFile)
# 过滤异常值，将其变为空值
"""data[u'销量'][(data[u'销量'] < 400) | (data[u'销量']) > 5000] = None 此行为错误代码，小括号将data[u'销量']括起来了"""
data[u'销量'][(data[u'销量'] < 400) | (data[u'销量'] > 5000)] = None # |与OR用法相同  ##正确写法是小括号应将data[u'销量'] > 5000括起来"""
# 自定义列向量插值函数
# s为列向量，n为被插值的位置，k为取前后的数据个数，默认为5
def ployinterp_column(s, n, k = 2):
    """# y = s[list(range(n - k, n)) + list(range(n + 1, n + 1 + k))] # 此行为错误代码 取值方法错误"""
    y = s.iloc[list(range(n - k, n)) + list(range(n + 1, n + 1 + k))] #应使用基于数字索引的iloc方法取值
    y = y[y.notnull()] # 剔除空值
    return lagrange(y.index, list(y))(n) # 插值并返回差值结果
# 逐个元素判断是否需要插值
for i in data.columns:
    for j in range(len(data)):
   if (data[i].isnull())[j]:
   """# data[i][j] = ployinterp_column(data[i], j)  # 此行为错误代码 取值方法错误"""
   data.loc[j, i] = ployinterp_column(data[i], j)  # 正确写法是使用基于自定义索引的loc方法取值
data.to_excel(outputFile)
print("success!")
========================
https://viper3.top/943/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！1.分布式文件系统
（1）计算机集群结构
集群的概念
集群是指将多台服务器整合在一起，每台服务器都实现相同的业务，做相同的事情。
每台服务器并不是缺一不可，它存在的作用主要是：
缓解并发压力、提升计算性能
单点故障转移问题
传统版集群结构示意
1.传统集群使用多个处理器和专用高级硬件的并行化处理装置
2.紧密/集中构造
阿姆达尔定律——并行度和可扩展性关系
普通版计算机集群结构
普及化的计算机集群，都是由普通硬件构成的，硬件成本上低、使用和开发的门槛降低 – 相互之间分散——所以也称分布式
（2）分布式文件系统结构
分布式计算机系统
业务分工和总体协调
大数据存储的解决途径
集中扩展模式
通过文件系统管理、存储数据
信息爆炸时代获取的数据成指数倍的增长，单纯通过增加硬盘个数来扩展计算机文件系统的存储容量的方式/以及专用的存储系统
分散存储组合 – 分布式
文件系统管理的物理存储资源不一定直接连接在本地节点上，而是通过计算机网络与节点（可简单的理解为一台计算机）相连，通过多节点…
解决存储和管理难题：
将固定于某个地点的某个文件系统，扩展到任意多个地点/多个文件系统，众多的节点组成一个文件系统网络。
每个节点可以分布在不同的地点，通过网络进行节点间的通信和数据传输。
人们在使用分布式文件系统时，无需关心数据是存储在哪个节点上、或者是从哪个节点获取的，只需要像使用本地文件系统一样管理和存储文件系统中的数据。
常见的分布式文件系统
HDFS集群系统的文件系统
总体的文件是通过某一种机制分布在各个计算机上：节点。这些节点分为两类：一类叫“主节点”（Master Node）或者也被称为“名称节点”（NameNode），另一类叫“从节点”（Slave Node）或者也被称为“数据节点”（DataNode）
2.HDFS简介
总体而言，HDFS要实现以下目标：
兼容廉价的硬件设备
流数据读写
大数据集
简单的文件模型
强大的跨平台兼容性
HDFS特殊的设计，在实现上述优良特性的同时，也使得自身具有一些应用局限性，主要包括以下几个方面：
不适合低延迟数据访问
无法高效率存储大量小文件
不支持多用户写入及任意修改文件
3.HDFS的相关概念
（1）块
HDFS默认一个块 64MB/128M，一个文件被分成多个块，以块作为存储单位
块的大小远远大于普通文件系统，可以最小化寻址开销
HDFS采用抽象的块概念可以带来以下几个明显的好处：
1）支持大规模文件存储：文件以块为单位进行存储，一个大规模文件可以被分拆成若干个文件块，不同的文件块可以被分发到不同的节点上，因此，一个文件的大小不会受到单个节点的存储容量的限制，可以远远大于网络中任意节点的存储容量。
2）简化系统设计：首先，大大简化了存储管理，因为文件块大小是固定的，这样就可以很容易计算出一个节点可以存储多少文件块；其次，方便了元数据的管理，元数据不需要和文件块一起存储，可以由其他系统负责管理元数据。
3）适合数据备份：每个文件块都可以冗余存储到多个节点上，大大提高了系统的容错性和可用性。
（2）名称节点和数据节点
HDFS主要组件的功能
名称节点的数据结构
在HDFS中，名称节点（NameNode）负责管理分布式文件系统的命名空间（Namespace），保存了两个核心的数据结构，即 FsImage 和 EditLog
FsImage 用于维护文件系统树以及文件树中所有的文件和文件夹的元数据
操作日志文件 EditLog 中记录了所有针对文件的创建、删除、重命名等操作
名称节点记录了每个文件中各个块所在的数据节点的位置信息
FsImage文件
FsImage 文件包含文件系统中所有目录和文件 inode 的序列化形式。每个 inode 是一个文件或目录的元数据的内部形式，并包含此类信息：文件的复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。对于目录，则存储修改时间、权限和配额元数据。
FsImage 文件没有记录文件包含哪些块以及每个块存储在哪个数据节点。而是由名称节点把这些映射信息保留在内存中，当数据节点加入 HDFS 集群时，数据节点会把自己所包含的块列表告知给名称节点，此后会定期执行这种告知操作，以确保名称节点的块映射是最新的。
名称节点的启动
在名称节点启动的时候，它会将 FsImage 文件中的内容加载到内存中，之后再执行 EditLog 文件中的各项操作，使得内存中的元数据和实际的同步，存在内存中的元数据支持客户端的读操作。
一旦在内存中成功建立文件系统元数据的映射，则创建一个新的 FsImage 文件和一个空的 EditLog 文件
名称节点起来之后，HDFS 中的更新操作会重新写到 EditLog 文件中，因为 FsImage 文件一般都很大（GB 级别的很常见），如果所有的更新操作都往 FsImage 文件中添加，这样会导致系统运行的十分缓慢，但是，如果往 EditLog 文件里面写就不会这样，因为 EditLog 要小很多。每次执行操作之后，且在向客户端发送成功代码之前，edits 文件都需要同步更新。
名称节点运行期间 EditLog 不断变大的问题
在名称节点运行期间，HDFS 的所有更新操作都是直接写到 EditLog 中，久而久之，EditLog 文件将会变得很大
虽然这对名称节点运行时候是没有什么明显影响的，但是，当名称节点重启的时候，名称节点需要先将 FsImage 里面的所有内容映像到内存中，然后再一条一条地执行 EditLog 中的记录，当 EditLog 文件非常大的时候，会导致名称节点启动操作非常慢，而在这段时间内 HDFS 系统处于安全模式，一直无法对外提供写操作，影响了用户的使用
如何解决？
答案是：SecondaryNameNode 第二名称节点
第二名称节点 是 HDFS 架构中的一个组成部分，它是用来保存名称节点中对 HDFS 元数据信息的备份，并减少名称节点重启的时间。SecondaryNameNode 一般是单独运行在一台机器上
数据节点（DataNode）
数据节点是分布式文件系统 HDFS 的工作节点，负责数据的存储和读取，会根据客户端或者是名称节点的调度来进行数据的存储和检索，并且向名称节点定期发送自己所存储的块的列表。
每个数据节点中的数据会被保存在各自节点的本地 Linux 文件系统中。
4.HDFS 体系结构
（1）HDFS 体系结构概述
HDFS 采用了主从（Master/Slave）结构模型，一个 HDFS 集群包括一个名称节点（NameNode）和若干个数据节点（DataNode）。名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。集群中的数据节点一般是一个节点运行一个数据节点进程，负责处理文件系统客户端的读/写请求，在名称节点的统一调度下进行数据库块的创建、删除和复制等操作。每个数据节点的数据实际上是保存在本地 Linux 文件系统中的。
（2）HDFS 命名空间管理
HDFS 的命名空间包含 目录、文件和块
在 HDFS1.0体系结构中，在整个 HDFS 集群中只有一个命名空间，并且只有唯一一个名称节点，该节点负责对这个命名空间进行管理
HDFS 使用的是传统的 分级文件体系，因此，用户可以 像使用普通文件系统一样，创建、删除目录和文件，在目录间转移文件，重命名文件等。
（3）通信协议
HDFS 是一个部署在集群上的分布式文件系统，因此，很多数据需要通过网络进行传输
所有的 HDFS 通信协议都是构建在 TCP/IP 协议基础之上的
客户端通过一个可配置的端口向名称节点主动发起 TCP 连接，并使用客户端协议与名称节点进行交互
名称节点和数据节点之间则使用数据节点协议进行交互
客户端与数据节点的交互是通过 RPC（Remote Procedure Call）来实现的。在设计上，名称节点不会主动发起 RPC，而是响应来自客户端和数据节点的 RPC 请求。
（4）客户端
客户端是用户操作 HDFS 最常用的方式，HDFS 在部署时都提供了客户端
HDFS客户端是一个库，暴露了 HDFS 文件系统接口，这些接口隐藏了 HDFS 实现中的大部分复杂性
严格来说，客户端并不算是 HDFS 的一部分
客户端可以支持打开、读取、写入等常见的操作，并且提供了类似 Shell 的命令行方式来访问 HDFS 中的数据
此外，HDFS 也提供了 Java API，作为应用程序访问文件系统的客户端编程接口
（5）HDFS 体系结构的局限性
HDFS 只设置唯一一个名称节点，这样做虽然大大简化了系统设计，但也带来了一些明显的局限性，具体如下：
1）**命名空间的限制：**名称节点是保存在内存中的，因此，名称节点能够容纳的对象（文件、块）的个数会受到内存空间大小的限制。
2）**性能的瓶颈：**整个分布式文件系统的吞吐量，受限于单个名称节点的吞吐量。
3）**隔离问题：**由于集群中只有一个名称节点，只有一个命名空间，因此，无法对不同应用程序进行隔离。
4）**集群的可用性：**一旦这个唯一的名称节点发生故障，会导致整个集群变得不可用。
5.HDFS 存储原理
（1）冗余数据保存
作为一个分布式文件系统，为了保证系统的容错性和可用性，HDFS 采用了多副本方式对数据进行冗余存储，通常一个数据块的多个副本会被分布到不同的数据节点上，如图所示，数据块 1 被分别存放到数据节点 A 和 C 上，数据块 2 被存放在数据节点 A 和 B 上。这种多副本方式具有以下几个优点：
1）加快数据传输速度
2）容易检查数据错误
3）保证数据可靠性
（2）数据存储策略
数据存放
第一个副本，放置在上传文件的数据节点；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点
第二个副本：放置在与第一个副本不同的机架的节点上
第三个副本：与第一个副本相同机架的其他节点上
更多副本：随机节点
数据读取
HDFS 提供了一个 API 可以确定一个数据节点所属的机架 ID，客户端也可以调用 API 获取自己所属的机架 ID
当客户端读取数据时，从名称节点获得数据块不同副本的存放位置列表，列表中包含了副本所在的数据节点，可以调用 API 来确定客户端和这些数据节点所属的机架 ID，当发现某个数据块副本对应的机架 ID 和客户端对应的机架 ID 相同时，就优先选择该副本读取数据，如果没有发现，就随机选择一个副本读取数据
（3）数据错误与恢复
HDFS 具有较高的容错性，可以兼容廉价的硬件，它把硬件出错看作一种常态，而不是异常，并设计了相应的机制检测数据错误和进行自动恢复，主要包括了一下几种情形：名称节点出错、数据节点出错和数据出错。
名称节点出错
名称节点保存了所有的元数据信息，其中，最核心的两大数据结构是 FsImage 和 Editlog，如果这两个文件发生损坏，那么整个 HDFS 实例将失效。因此，HDFS 设置了备份机制，把这些核心文件同步复制到备份服务器 SecondaryNameNode 上。当名称节点出错时，就可以根据备份服务器 SecondaryNameNode 中的 FsImage 和 Editlog 数据进行恢复。
数据节点出错
每个数据节点会定期向名称节点发送“心跳”信息，向名称节点报告自己的状态
当数据节点发生故障，或者网络发生断网时，名称节点就无法收到来自一些数据节点的心跳信息，这时，这些数据节点就会被标记为“宕机”，节点上面的所有数据都会被标记为“不可读”，名称节点不会再给它们发送任何 I/O 请求
这时，有可能出现一种情况，即由于一些数据节点的不可用，会导致一些数据块的副本数量小于冗余因子
名称节点会定期检查这种情况，一旦发现某个数据块的副本数量小于冗余因子，就会启动数据冗余复制，为它生成新的副本
HDFS 和其他分布式文件系统的最大区别就是可以调整冗余数据的位置
数据出错
网络传输和磁盘错误等因素，都会造成数据错误
客户端在读取到数据后，会采用 md5 和 sha1 对数据块进行校验，以确定读取到正确的数据
在文件被创建时，客户端就会对每一个文件块进行信息摘录，并把这些信息写入到同一个路径的隐藏文件里面
当客户端读取文件的时候，会先读取该信息文件，然后，利用该信息文件对每个读取的数据块进行校验，如果校验出错，客户端就会请求到另外一个数据节点读取该文件块，并且向名称节点报告这个文件块有错误，名称节点会定期检查并且重新复制这个块
6.HDFS 数据读写过程
读取文件
import java.io.BufferedReader;
import java.io.InputstreamReader;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Filesystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.FSDataInputStream;
public class Chapter3{
    public static void main (String[] args) {
   try {
  Configuration conf = new Configuration();
  conf.set("fs.defaultFS", "hdfs://localhost:9000");
  conf.set("fs.hdfs.impl", "org.apache.hadoop.hdfs.DistributedFileSystem");
  FileSystem fs = Filesystem.get(conf);
  Path file = new Path("test");
  FSDataInputstream getIt = fs.open(file);
  BufferedReader d = new BufferedReader(new InputStreamReader(getIt));
  String content = d.readLine(); //读取文件一行
  System.out.println(content);
  d.close(); //关闭文件
  fs.close(); //关闭hdfs
   } catch (Exception e) {
  e.printstackTrace();
 }
    }
}
写入文件
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.Path;
public class Chapter3 {
    public static void main(String[] args) {
   try {
  Configuration conf = new Configuration();
  conf.set("fs.defaultFS", "hdfs://localhost:9000");
  conf.set("fs.hdfs.impl", "org.apache.hadoop.hdfs.DistributedFileSystem");
  FileSystem fs -FileSystem.get(conf);
  byte[] buff = "Hello world".getBytes(); //要写入的内容
  String filename = "test"; //要写入的文件名
  FSDataOutputStream os = fs.create(new Path(filename));
  os.write(buff, 0, buff.length);
  System.out.println("Create:" + filename);
  os.close();
  fs.close();
   } catch (Exception e) {
  e.printStackTrace();
   }
    }
}
FileSystem 是一个通用文件系统的抽象基类，可以被分布式文件系统继承，所有可能使用 Hadoop 文件系统的代码，都要使用这个类
Hadoop 为 FileSystem 这个抽象类提供了多种具体实现
DistributedFileSystem 就是 FileSystem 在 HDFS 文件系统中的具体实现
FileSystem 的 open() 方法返回的是一个输入流 FSDataInputStream 对象，在 HDFS 文件系统中，具体的输入流就是 DFSInputStream；FileSystem 中的 create() 方法返回的是一个输出流 FSDataOutputStream 对象，在 HDFS 文件系统中，具体的输出流就是 DFSOutputStream。
Configuration conf = new Configuration();
conf.set("fs.defaultFS","hdfs://localhost:9000");
conf.set("fs.hdfs.impl" ,"org.apache.hadoop.hdfs.DistributedFileSystem");
FileSystem fs = FileSystem.get(conf);
FSDatalnputStream in = fs.open(new Path(uri));
FSDataOutputStream out = fs.create(new Path(uri));
（1）读数据的过程
（2）写数据的过程
7.HDFS 编程实践
Hadoop 提供了关于 HDFS 在 Linux 操作系统上进行文件操作的常用 Shell 命令以及 Java API 。同时还可以利用 Web 界面查看和管理 Hadoop 文件系统
备注：Hadoop 安装成功后，已经包含 HDFS 和 MapReduce，不需要额外安装。而 HBase 等其他组件，则需要另外下载安装。
在学习 HDFS 编程实践前，我们需要启动 Hadoop 。执行如下命令：
cd /usr/local/hadoop
./bin/hdfs namenode -format #格式化hadoop的hdfs文件系统
./sbin/start-dfs.sh #启动hadoop
（1）HDFS 常用命令
（2）HDFS 的 Web 界面
（3）HDFS 常用 Java API 及应用实例
本章小结
========================
https://viper3.top/107/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！WordPress仪表板不允许您对媒体文件进行最用户友好的组织。 WordPress仪表板中的媒体部分缺少文件夹结构，该文件夹结构使您可以轻松地对网站上的所有媒体文件进行分类和排序。
这会带来更加困难的帖子和页面创建体验，并使网站更新比需要的过程更加耗时。FileBird WordPress媒体库文件夹插件可让您控制媒体库，并专注于以轻松的方式构建和更新网站。 通过使用文件夹系统，此功能强大的WordPress插件可让您创建一个嵌套的文件夹系统，该系统可根据您运行网站的方式进行组织。
本文将向您展示如何立即组织媒体库并创建引人注目的美食博客！
我们将要建设的
无论您运行的是哪种类型的WordPress网站，都需要一种在网站后端组织媒体文件的方法。 在本文中，我们将成为一个食物博客的所有者，该博客汇集了各种食物的食谱。 当前默认媒体库不允许我们整理食物照片，以便我们可以轻松地将这些食谱放到我们网站的不同页面上。
借助FileBird WordPress插件，我们将为食物博客上的食谱类型创建三个专用文件夹：面食，海鲜和肉类。 为了进一步组织媒体库，我们将在这三类食物中添加子文件夹。 有了这个组织系统之后，我们将开始使用所有食谱和组织好的媒体库来构建博客页面。
这是一张照片，显示我们整理图像并构建食谱页面后，其中包含食谱的博客页面的外观。
整理媒体库
安装File Bird WordPress插件后，转到WP Dashboard> Media> Library。这将打开默认的媒体库。 您已经注意到，媒体库的左侧出现了一个新的部分，称为文件夹。 这是我们创建组织系统的地方。
我们要建立食物博客的第一步是上传所有不同类别食物的照片。 我们将单击添加新>选择文件，然后选择六个要上传的食物图像。
这些图像上传后，就可以开始对其进行分类了。 如前所述，我们要创建三种食物类别。 在媒体库仪表板左上方的“文件夹”标题旁边，单击“新建文件夹”按钮。 一个新文件夹将出现在FileBird文件夹列中，我们将输入Pasta。 对海鲜和肉类重复两次以上此过程。
因为我们希望有一个更高层次的组织，以便我们可以快速浏览媒体库，所以我们将为每个父类别创建一个子文件夹。 要添加这些子文件夹，我们将单击第一个文件夹，标记为Pasta。 然后，我们将单击“新文件夹”按钮，这将在Pasta下添加一个子文件夹。 我们将在此处添加两个子文件夹，分别是白汁和红汁。
我们还将对其他两个父类别重复此过程。 对于肉类，我们将添加鸡肉和牛肉子文件夹。 对于海鲜类别，我们将添加虾和三文鱼子文件夹。
至于我们需要的食物博客组织，这些子文件夹就是我们需要的子文件夹。 根据您网站的需求，可以创建更多子类别。 如果需要，您最多可以创建七个不同的子类别。
同样，您在媒体库中创建的文件夹也将被拖放。 因此，如果您需要随时重新排列文件夹系统，只需将它们拖放到所需位置即可。
为了完成媒体的组织，我们将每个图像拖放到媒体库仪表板中的相应文件夹中。
创建美食博客食谱页面
现在是时候创建包含食谱和我们组织的图像的实际页面了。 从WordPress管理侧栏中选择“页面”>“添加新内容”。
我们将添加到博客中的第一组食谱将是意大利面。 在标题中，输入Pasta。 在此，我们将在H4标题中键入Red Sauce Pasta。 在标题下方，我们将添加意大利面图片。 在默认的WordPress页面构建器中，我们将单击图像图标以添加我们的面食图像。 单击“媒体库”按钮旁边，然后将出现一个弹出窗口，其中带有媒体库网格以及左侧的FileBird文件夹系统。 现在，我们将在Red Sauce子文件夹中选择我们的面食图像。
现在是时候将我们的说明和配料添加到食谱页面，以便我们的博客查看者可以在家复制我们的食谱了。 我们将其插入到刚添加的图像下方。
尽管目前我们的媒体库中没有大量图像，但是您仍然可以看到该组织确实在帮助您尽快创建帖子和页面。
我们将对我们拥有的每个食谱重复此过程。 我们将再创建两个名为“海鲜和肉类”的页面，并添加标题，图像，成分和说明。
你有它！ 我们成功地将图像添加到我们的媒体库，将它们组织在文件夹系统中，并快速创建了食谱博客文章。
要观看媒体的组织和美食博客的创建，请观看下面的视频。
充分利用插件
FileBird WordPress插件是一个基本的实用程序插件，如果您要向网站添加媒体，则必须使用它。 该插件的功能非常简单。 如上所述，它允许您创建默认情况下在WordPress中不存在的组织系统。
在我们的示例中，我们将图像添加到我们的媒体库中，并按食物类型组织了图像，以使其在我们的食物博客中得以展示。 但是，还有其他方法可以使用文件夹系统来组织媒体库。 以下是组织图书馆时要考虑的一些有用提示。
1.考虑一下您将拥有哪种媒体
如果您正在运行一个电子商务服装网站，则将需要多个子类别。 例如，您可能正在销售衬衫，并将其作为父类别。 在此父类别下，您可以具有大小，颜色和品牌。 更进一步，您可以拥有第二和第三子类别。 在衬衫下，您可能有一个子类别，其中包含“成人”和“儿童”尺寸的文件夹，然后是“成人”下的另一个子类别，分别具有小，中和大文件夹。
2.按页面或帖子标题进行组织
如果要添加已知将在特定页面或帖子上显示的媒体，则始终可以创建具有该页面或帖子标题的文件夹，以便在创建页面时可以快速导航至它们。
3.按日期整理
WordPress允许您查看在特定月份添加的媒体，但不能按年份或日期查看。 您可以为某些天创建的媒体创建文件夹，例如用于事件照片。
结论
FileBird WordPress插件可能不是功能最丰富，最令人兴奋的插件，但对于WordPress网站所有者而言，这绝对是必需的。 现代网站要求您在网站上显示图像，视频和音频，以提供视觉上更令人愉悦的体验。 FileBird插件使您能够组织网站上的所有媒体，从而节省时间并专注于运营企业和网站的更重要任务。
========================
https://viper3.top/764/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！
GitHubViper373/League-of-Legends-Pro-League-DataAnalytics
本人第一次Python项目实战，轻喷
========================
https://viper3.top/1122/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！一、安装JDK和Hadoop
1.安装JDK
【第1步】卸载镜像自带JDK
###使用管理员账户
su root
### 查询出系统自带的jdk
rpm -qa|grep java
### 删除系统自带的jdk
rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.261-2.6.22.2.el7_8.x86_64
rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.262.b10-1.el7.x86_64
rpm -e --nodeps java-1.8.0-openjdk-1.8.0.262.b10-1.el7.x86_64
rpm -e --nodeps java-1.7.0-openjdk-1.7.0.261-2.6.22.2.el7_8.x86_64
【第2步】安装JDK1.8
### 创建java目录存放自己的jdk
cd /usr/local
mkdir java
cd java
### 安装在线导入安装包的插件
yum -y install lrzsz
rz
tar -zxvf [名]
【第3步】配置环境变量
### 配置环境变量
vim /etc/profile
#JAVA_HOME
export JAVA_HOME=/usr/local/java/jdk1.8.0_361
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export PATH=$PATH:$JAVA_HOME/bin
【第4步】验证环境变量，并查看JDK版本
### 使刚才配置的环境变量生效
source /etc/profile
javac
### 查看你安装的jdk信息
java -version
2.安装Hadoop
【第1步】上传新的hadoop-2.7.5.tar.gz软件到/usr/local/
### 安装Hadoop
### 【第1步】上传新的hadoop-2.7.5.tar.gz软件到/usr/local/
cd /usr/local
rz
【第2步】解压缩hadoop-2.7.5.tar.gz软件到/usr/local/
### 【第2步】解压缩hadoop-2.7.5.tar.gz软件到/usr/local/
tar -zxvf hadoop-2.7.5.tar.gz
mv hadoop-2.7.5 hadoop
【第3步】配置环境变量
### 【第3步】配置环境变量
vim /etc/profile
#HADOOP_HOME
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
### 使刚才配置的环境变量生效
source /etc/profile
二、修改Hadoop配置文件
【第4步】修改core-site.xml
### 【第4步】修改core-site.xml
cd /usr/local/hadoop/etc/hadoop
vim core-site.xml
<configuration>
    <!--指定HDFS中NameNode的地址, hadoop001为host中配置的主机名 -->
    <property>
   <name>fs.default.name</name>
   <value>hdfs://master:9000</value>
    </property>
    <!--指定hadoop运行产生文件（DataNode）的存储目录 -->
    <property>
   <name>hadoop.tmp.dir</name>
   <value>/usr/local/hadoop/hdfs/tmp</value>
    </property>
</configuration>
【第5步】修改hadoop-env.sh
### 【第5步】修改hadoop-env.sh
vim hadoop-env.sh
export JAVA_HOME=/usr/local/java/jdk1.8.0_361
【第6步】修改yarn-env.sh
### 【第6步】修改yarn-env.sh
vim yarn-env.sh
export JAVA_HOME=/usr/local/java/jdk1.8.0_361
【第7步】修改mapred-site.xml
### 【第7步】修改mapred-site.xml
cp mapred-site.xml.template mapred-site.xml
vim mapred-site.xml
<configuration>
    <property>
   <name>mapreduce.framework.name</name>
   <value>yarn</value>
    </property>
    <!--jobhistory properties -->
    <property>
   <name>mapreduce.jobhistory.address</name>
   <value>master:10020</value>
    </property>
    <property>
   <name>mapreduce.jobhistory.webapp.address</name>
   <value>master:19888</value>
    </property>
</configuration>
【第8步】修改yarn-site.xml
### 【第8步】修改yarn-site.xml
hostnamectl set-hostname master  # 先修改主机名为master
vim yarn-site.xml
<configuration>
    <property>
   <name>yarn.resourcemanager.hostname</name>
   <value>master</value>
    </property>
    <property>
   <name>yarn.resourcemanager.address</name>
   <value>${yarn.resourcemanager.hostname}:8032</value>
    </property>
    <property>
   <name>yarn.resourcemanager.scheduler.address</name>
   <value>${yarn.resourcemanager.hostname}:8030</value>
    </property>
    <property>
   <name>yarn.resourcemanager.webapp.address</name>
   <value>${yarn.resourcemanager.hostname}:8088</value>
    </property>
    <property>
   <name>yarn.resourcemanager.webapp.https.address</name>
   <value>${yarn.resourcemanager.hostname}:8090</value>
    </property>
    <property>
   <name>yarn.resourcemanager.resource-tracker.address</name>
   <value>${yarn.resourcemanager.hostname}:8031</value>
    </property>
    <property>
   <name>yarn.resourcemanager.admin.address</name>
   <value>${yarn.resourcemanager.hostname}:8033</value>
    </property>
    <property>
   <name>yarn.nodemanager.local-dirs</name>
   <value>/data/hadoop/yarn/local</value>
    </property>
    <property>
   <name>yarn.log-aggregation-enable</name>
   <value>true</value>
    </property>
    <property>
   <name>yarn.nodemanager.remote-app-log-dir</name>
   <value>/data/tmp/logs</value>
    </property>
    <property>
   <name>yarn.log.server.url</name>
   <value>http://master:19888/jobhistory/logs/</value>
   <description>URL for job history server</description>
    </property>
    <property>
   <name>yarn.nodemanager.vmem-check-enabled</name>
   <value>false</value>
    </property>
    <property>
   <name>yarn.nodemanager.aux-services</name>
   <value>mapreduce_shuffle</value>
    </property>
    <property>
   <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
   <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
   <name>yarn.nodemanager.resource.memory-mb</name>
   <value>2048</value>
    </property>
    <property>
   <name>yarn.scheduler.minimum-allocation-mb</name>
   <value>512</value>
    </property>
    <property>
   <name>yarn.scheduler.maximum-allocation-mb</name>
   <value>4096</value>
    </property>
    <property>
   <name>mapreduce.map.memory.mb</name>
   <value>2048</value>
    </property>
    <property>
   <name>mapreduce.reduce.memory.mb</name>
   <value>2048</value>
    </property>
    <property>
   <name>yarn.nodemanager.resource.cpu-vcores</name>
   <value>1</value>
    </property>
</configuration>
【第9步】修改slaves文件
### 【第9步】修改slaves文件
vim slaves
slave1
slave2
slave3
【第10步】修改hdfs-site.xml
### 【第10步】修改hdfs-site.xml
vim hdfs-site.xml
<configuration>
    <property>
   <name>dfs.namenode.name.dir</name>
   <value>file:///usr/local/hadoop/hdfs/name</value>
    </property>
    <property>
   <name>dfs.datanode.data.dir</name>
   <value>file:///usr/local/hadoop/hdfs/data</value>
    </property>
    <property>
   <name>dfs.namenode.secondary.http-address</name>
   <value>master:50090</value>
    </property>
    <property>
   <name>dfs.replication</name>
   <value>3</value>
    </property>
</configuration>
【第11步】修改/etc/hosts文件
### 【第11步】修改/etc/hosts文件
ip addr
vim /etc/hosts
192.168.31.116 master master.localdomain
192.168.31.117 slave1 slave1.localdomain
192.168.31.118 slave2 slave2.localdomain
192.168.31.119 slave3 slave3.localdomain
三、克隆虚拟机
### 关闭master，克隆到slave1
rm –rf /etc/udev/rules.d/70-persistent-net.rules
cd /etc/udev/rules.d
ll
cp 70-persistent-ipoib.rules 70-persistent-ipoib.rules.bak
ll
rm 70-persistent-ipoib.rules
y
ll
ifconfig -a
四、配置SSH免密
ssh-keygen -t rsa
ssh-copy-id -i /root/.ssh/id_rsa.pub slave1
ssh-copy-id -i /root/.ssh/id_rsa.pub slave2
ssh-copy-id -i /root/.ssh/id_rsa.pub slave3
ssh slave1
ssh slave2
ssh slave3
五、配置时间同步
### （1）安装NTP服务。在各节点
yum -y install ntp
### （2）设置master节点为NTP服务主节点，
vim /etc/ntp.conf
注释掉以server开头的行 并添加:
restrict 192.168.0.0 mask 255.255.255.0 nomodify notrap
server 127.127.1.0
fudge 127.127.1.0 stratum 10
### （3）在所有slave节点中配置NTP，同样修改/etc/ntp.conf文件，注释掉server开头的行，并添加:
server master
### （4）执行命令
systemctl stop firewalld.service
systemctl disable firewalld.service # 永久性关闭防火墙，主节点和从节点都要关闭。
### （5）启动NTP服务。
### ①在master节点执行命令
systemctl start ntpd.service
systemctl enable ntpd.service
### ②在slave1、slave2、slave3上执行命令
ntpdate master # 即可同步时间
### ③在slave1、slave2、slave3上分别执行
systemctl start ntpd.service
systemctl enable ntpd.service # 即可启动并永久启动NTP服务。
六、格式化hdfs
【第1步】查看防火墙状态并永久关闭（命令看配置时间同步的4）
【第2步】创建HDFS存储目录
cd /usr/local/hadoop
mkdir hdfs
cd hdfs
mkdir data name tmp
【第3步】复制hadoop和/etc/profile到其它节点，并使四台机器环境变量生效
scp -r /usr/local/hadoop slave1:/usr/local
scp -r /usr/local/hadoop slave2:/usr/local
scp -r /usr/local/hadoop slave3:/usr/local
scp  /etc/profile slave1:/etc
scp  /etc/profile slave2:/etc
scp  /etc/profile slave3:/etc
# source三个从节点
source /etc/profile
七、启动集群
【第1步】格式化namenode
hadoop namenode -format # 在此之前一定要查看/usr/local/hadoop/hdfs下的三个文件夹中有无内容，无内容才可格式化
【第2步】启动HDFS并使用jps查看进程
start-all.sh # 启动hdfs
jps
Master
Slave
八、查看HDFS管理页面
http://192.168.31.116:50070/dfshealth.html#tab-overview
九、HDFS Datenodes页面
http://192.168.31.116:50070/dfshealth.html#tab-datanode
十、访问Yarn管理页面
http://192.168.31.116:8088
十一、关闭集群
stop-all.sh
========================
https://viper3.top/492/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！如果你还没有安装WordPress，详见前文
轻代码开发——使用宝塔Windows面板+WordPress建站
WordPress的系统要求
数据库– MySQL 5.0＆amp; plus;
Web服务器 –
WAMP(Windows)
LAMP(Linux)
XAMPP(Multi-platform)
MAMP(Macintosh)
操作系统– 跨平台
浏览器支持– IE(Internet Explorer 8＆amp; plus;)，Firefox，Google Chrome，Safari，Opera
PHP兼容性– PHP 5.2＆amp; plus;
安装向导
将WordPress设置到您的系统很容易。 以下步骤介绍如何在系统上本地设置WordPress。
步骤(1)– 提取下载的WordPress文件夹，并将其上传到您的Web服务器或本地主机。
步骤(2)– 打开浏览器并导航到您的WordPress文件路径，然后您将获得WordPress安装程序的第一个屏幕，如下面的屏幕所示。 在我们的例子中，路径是localhost / <Your_wordpress_folder>。
选择您的WordPress的语言，然后单击Continue。
步骤(3)– 在此步骤中，您可以在继续安装WordPress之前查看数据库所需的信息。
点击Let’s go!
步骤(4)– 在这里，您必须输入有关MySQL数据库的信息，如下面的屏幕所述。
Database Name– 输入在MySQL数据库中为WordPress创建的数据库名称。
Username– 输入MySQL数据库的用户名。
Password– 输入您为MySQL数据库设置的密码。
Database Host– 写入主机名，默认情况下为localhost。
Table Prefix– 用于在数据库表中添加前缀，这有助于在同一数据库上运行多个站点。 它采用默认值。
填写所有信息后，点击Submit按钮。
步骤(5)– WordPress检查数据库设置，并给出确认屏幕，如下面的快照所示。
点击RUN the install
步骤(6)– 输入管理信息。
它包含以下字段 –
Site Title– 输入要在WordPress中创建的网站的名称。
Username– 在登录WordPress时根据您的选择输入用户名。
Password twice– 输入两次密码以保护您的网站。
Your E-mail– 输入您的电子邮件地址，以帮助恢复密码或任何更新。
Privacy– 允许搜索引擎在选中此复选框后对此网站编制索引。
填写完所有信息后，单击Install WordPress按钮。
步骤(7)– 安装成功后，您将看到一个显示成功的屏幕，如以下屏幕所示。
您可以查看在WordPress中添加的用户名和密码详细信息。
单击Log In按钮。
步骤(8)– 点击登录后，您将获得一个WordPress管理面板，如下面的屏幕所示。
========================
https://viper3.top/1117/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！
上期将Hadoop集群搭建与配置完成了，接下来我们要进行一些Hadoop的基础操作来测试Hadoop集群（虚拟机克隆在此处不再赘述“包括一些修改网络配置，hosts文件等等的操作”）
一、查看Hadoop集群的基本信息
1.查询集群的存储系统信息
http://master:50070
显示各数据节点的存储信息
http://master:50070/dfshealth.html#tab-datanode
显示HDFS在线数据节点的信息
### 1.显示HDFS在线数据节点的信息命令
hdfs dfsadmin -report live
2.查询集群的计算资源信息
http://master:8088/cluster/nodes
节点slave1的计算资源信息
slave1:8042
二、上传文件到HDFS目录
1.掌握HDFS的基本操作
（1）创建新目录/user/dfstest
### 2.创建新目录/user/dfstest
hdfs dfs -mkdir -p /user/dfstest
（2）上传文件与下载文件
### 3.文件上传命令
# 创建文件a.txt
touch a.txt
# 修改a.txt内容
vim a.txt
# 显示a.txt内容
cat a.txt
# 将文件从本地文件复制到HDFS文件系统
hdfs dfs -copyFromLocal a.txt /user/dfstest
# 将文件从本地文件移动到HDFS文件系统并进行重命名(本地文件会删除)
hdfs dfs -moveFromLocal a.txt /user/dfstest/b.txt
# 将文件从本地文件上传到HDFS文件系统并进行重命名
hdfs dfs -put a.txt /user/dfstest/c.txt
### 4.文件下载命令
# 将文件从HDFS文件系统复制到本地文件系统
hdfs dfs -copyToLocal /user/dfstest/a.txt
# 获取HDFS文件系统上指定路径的文件到本地文件系统
hdfs dfs -get /user/dfstest/c.txt
（3）查看文件内容
# 查看HDFS文件内容
hdfs dfs -cat /user/dfstest/a.txt
# 获取HDFS文件最后1024字节
hdfs dfs -tail /user/dfstest/b.txt
（4）删除文件或目录
# 创建一个测试目录rmdir
hdfs dfs -mkdir -p /user/dfstest/rmdir
# 删除HDFS上的文件
hdfs dfs -rm /user/dfstest/c.txt
# 删除HDFS指定目录
hdfs dfs -rmdir /user/dfstest/rmdir
2.任务实现
（1）把本地计算机硬盘中的数据文件email_log.txt传输到集群服务器(master)的本地目录/root/hadoop/，打开SecureCRT,连接集群服务器的master节点，使用rz命令上传文件
### 7.实例.将本地文件email_log.txt文件上传到HDFS
### 【第一步】将本地计算机硬盘的数据文件email_log.txt传输到集群服务器master的本地目录/home/hadoop/
su root
rz
（2）在集群服务器(master)的终端执行HDFS命令，上传email_log.txt到HDFS目录/user/root/
### 【第二步】在HDFS创建新目录/user/root
hdfs dfs -mkdir -p /user/root
### 【第三步】在集群服务器(master)的终端执行 HDFS 命令，上传 email_log.txt 到 HDFS 目录/user/root/
hdfs dfs -put /home/hadoop/email_log.txt /user/root/
检查文件email_log.txt的内容
检查文件email_log.txt的文件块信息
三、运行首个MapReduce任务
1.提交MapReduce任务给集群运行
使用hadoop jar命令提交MapReduce任务命令
### 8.使用hadoop jar命令提交MapReduce任务命令
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar wordcount /user/root/email log.txt /user/root/output
执行统计登录次数程序的命令
### 9.执行估计PI值的任务命令
hadoop jar /usr/local/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar pi 10 100
### 10.更改参数执行估计PI值的任务命令
hadoop jar /usr/local/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar pi 30 5000
四、管理多个MapReduce任务
1.查询MapReduce任务
2.中断MapReduce任务
========================
https://viper3.top/637/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！
<span id="sitetime"></span>
<script language=javascript>
    function siteTime(){
   window.setTimeout("siteTime()", 1000);
   var seconds = 1000;
   var minutes = seconds * 60;
   var hours = minutes * 60;
   var days = hours * 24;
   var years = days * 365;
   var today = new Date();
   var todayYear = today.getFullYear();
   var todayMonth = today.getMonth()+1;
   var todayDate = today.getDate();
   var todayHour = today.getHours();
   var todayMinute = today.getMinutes();
   var todaySecond = today.getSeconds();
   /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
   year - 作为date对象的年份，为4位年份值
   month - 0-11之间的整数，做为date对象的月份
   day - 1-31之间的整数，做为date对象的天数
   hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
   minutes - 0-59之间的整数，做为date对象的分钟数
   seconds - 0-59之间的整数，做为date对象的秒数
   microseconds - 0-999之间的整数，做为date对象的毫秒数 */
   var t1 = Date.UTC(2016,12,01,00,00,00); //北京时间2016-12-1 00:00:00
   var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
   var diff = t2-t1;
   var diffYears = Math.floor(diff/years);
   var diffDays = Math.floor((diff/days)-diffYears*365);
   var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
   var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
   var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
   document.getElementById("sitetime").innerHTML=" 已运行"+diffYears+" 年 "+diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
    }
    siteTime();
</script>
访问https://rfzf.top，左侧栏公告为效果实现
========================
https://viper3.top/952/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！曲线救国 搞定初值
前期我们讲到使用“不蒜子”实现两行代码统计网站数据
关于“不蒜子”
简单来说，“不蒜子”是提供静态页面计数功能的一个第三方服务（欲了解详情可拜访其主页和文档），用户只需要在静态的html页面中插入一行脚本和一行标签，即可实现计数功能，官方说明如下（带下划线加粗字是重点，要考！）
静态网站建站现在有很多快速的技术和平台，但静态是优点也有缺点，由于是静态的，一些动态的内容如评论、计数等等模块就需要借助外来平台，评论有“多说”，计数有“不蒜”！
“不蒜子”与百度统计谷歌分析等有区别：“不蒜子”可直接将访问次数显示在您在网页上（也可不显示）；对于已经上线一段时间的网站，“不蒜子”允许您初始化首次数据。
普通用户只需两步走：一行脚本+一行标签，搞定一切。追求极致的用户可以进行意DIY。
实现原理
“不蒜子”的实现原理也很简单，经初步分析，在引入的JS(JavaScript)脚本中，会把当前页面url（或某种唯一标识）注册到其第三方服务器，服务器上保存着url与对应的计数值，点击页面后通过JS更新服务器上的计数值，并在页面初始化时在本地标签加载、显示计数值。
算法a：pv的方式，单个用户连续点击n篇文章，记录n次访问量。
算法b：uv的方式，单个用户连续点击n篇文章，只记录1次访客数。
如果你是用的hexo，打开themes/你的主题/layout/_partial/footer.ejs添加即可。
实例效果参考：
http://liam0205.me
http://gameknife.github.io
http://read.mobi
http://pgqlife.info
http://sdxy0506.github.io
http://www.gcrimson.com
http://libk.net
http://ztyoung.me
http://blog.itmyhome.com
虽然静态页面弱爆了，但JS很强大啊！
需求分析
访问量是一个网站的主要指标（不是必要，如写博客更重要的是思考和学习），网页计数功能也成了我们的一个选择，像百度统计、谷歌统计等后台统计工具非常强大，但要想直接在页面（特别是静态页面）展示数据，“不蒜子”或许是你的不二之选。
但对于那些已经有一定访问量的老站点，访问量需要在原来的数据基础上计算，这就是所谓的“初始化首次数据”。
可看到其实“不蒜子”其实有提供“初始化首次数据”的功能，在文档中也有写到：
Q：我的网站已经运行一段时间了，想初始化访问次数怎么办？
A：请先注册登录，自行修改阅读次数。
太好了，于是兴奋地点击主页右上角的“登录”按钮……
看看文档下面的评论，应该有网友遇到同样问题，果不出我所料……原来是已经被作者搁置了一年多的功能。
分析问题
不蒜子之所以被称为「geek 的计数器」，就是因为它的安装使用非常简单——只需要加载计数器 js 脚本，以及使用 span标签显示计数器结果就可以了。其余所有的事情，都交给用户的css去控制。因此，自然，这个「所有的事情」也包括了最终显示的值是多少。因此，我们可以在最终显示的数字上做一些手脚。
思路如下：不直接显示计数值，每次显示之前先把拿到的计数值加上一个初始值，再进行显示，而这个中间处理可通过JS/JQuery来完成。
曲线救国——利用JS/JQuery纠正计数值
按“不蒜子”官方教程提示，在需要显示计数的位置插入对应的两行html代码，即可实现显示网站访问量（注意uv是一个IP记一次，而pv是每刷新一次记一次）。
一般解法
不蒜子的站点 PV 对应的标签是这样的
<span id="busuanzi_value_site_pv"></span>
既然如此，我们只需要在页面上用 js 取得这个标签中的值，而后加上一个偏移量作为初始值就可以了。如果使用 jQuery，可以这样做
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
    $(document).ready(
   var busuanziSiteOffset = parseInt(100000);
   function fixCount() {
  if ($("#busuanzi_container_site_pv").css("display") != "none") {
 $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + busuanziSiteOffset);
  }
   }
    );
</script>
余下唯一的问题，就是不蒜子的 js 代码，是通过异步的方式加载的。而在其加载完成之前，上述span标签会整个被隐藏起来，不可见。于是，这样的朴素的修复就会失效了。
对付「异步」，一个朴素的处理方式是定期轮询。比如这样
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
    $(document).ready(function() {
   var int = setInterval(fixCount, 100);
   var busuanziSiteOffset = parseInt(10000);
   function fixCount() {
  if ($("#busuanzi_container_site_pv").css("display") != "none") {
 clearInterval(int);
 $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + busuanziSiteOffset);
  }
   }
    });
</script>
Hexo 的解法
在上面的分析中，我们实际上已经有了完整的解法。不过，这样的解法可定制性非常差。试想，在需要修改初始值的时候，都需要深入到代码中去，而后修改var busuanziSiteOffset = parseInt(10000);的值。这种事情，想想就令人崩溃。
对于 Hexo 来说，在站点或主题配置中的变量，可以在主题模版中引用得到。于是，我们可以这样做。
#config.yml
busuanzi: true
busuanzi_site_offset: 100000
以及这样做。
#hexo_footer.swig
{% if theme.busuanzi %}
<!-- 不蒜子 -->
<script async src="//cdn.busuanzi.ibruce.info/cdn/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<!-- 不蒜子计数初始值纠正 -->
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
    $(document).ready(function() {
   var int = setInterval(fixCount, 100);
   var busuanziSiteOffset = parseInt({{ theme.busuanzi_site_offset }});
   function fixCount() {
  if ($("#busuanzi_container_site_pv").css("display") != "none") {
 clearInterval(int);
 $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + busuanziSiteOffset);
  }
   }
    });
</script>
{% endif %}
代码解释
$(document).ready方法在文档加载后执行，即让网页加载完毕后执行我们的JS代码，再用setInterval设置50毫秒周期性调用fixCount()方法。countOffset这个变量就是我们要加上的初始值了（可通过网站之前的统计工具如百度统计谷歌统计查看到），这里设为20000。在重头戏fixCount()方法内，先判断标签的display属性，当不为”none”时（异步加载数据完成）获得原始数值，加上自定义的额初始值后再写入标签，最后关掉Interval，大功告成！
这样，当我们访问页面时，会不停的检测标签的状态，一旦计数值加载出来就加上初始值纠正，再显示，解决了“不蒜子”不能初始化首次数据的问题。
我的不蒜子代码（可一键复制）
切记修改初始数值！！！
<!-- 引入不蒜子计数 -->
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<!-- 不蒜子计数初始值纠正 -->
<script>
    $(document).ready(function() {
   var delay = setInterval(fixCount, 50);  // 50ms周期检测函数
   var countOffsetpv = 10945;  // 初始化首次pv数据
   var countOffsetuv = 203;  // 初始化首次uv数据
   function fixCount() {    
  if ($("#busuanzi_container_site_pv").css("display") != "none")
  {
    $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffsetpv); // 加上初始数据 
    clearInterval(delay); // 停止检测
  }  
  if ($("#busuanzi_container_site_uv").css("display") != "none")
  {
    $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffsetuv); // 加上初始数据 
    clearInterval(delay); // 停止检测
  }
   }    
    });
</script>
<!-- 不蒜子主体显示部分 -->
<span id="busuanzi_container_site_pv" style='display:none'>
    📬本站已被点击
    <span id="busuanzi_value_site_pv" style="color:#ffff00">
   <i class="fa fa-spinner fa-spin"></i>
    </span>次
</span>
<br>
<span id="busuanzi_container_site_uv" style='display:none'>
    ⌛已为
    <span id="busuanzi_value_site_uv" style="color:#ffff00">
   <i class="fa fa-spinner fa-spin"></i>
    </span>位踩坑者提供港湾
</span>
效果如下
========================
https://viper3.top/805/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！1.安装该第三方库
pip install graphviz 
# 若已安装 则需要先卸载：
pip uninstall graphviz
# 若由于网速原因不能下载 可以使用
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple graphviz
2.下载graphviz安装包
点击此处官网下载
本人使用的是6.0.2版本，可点此下载
可选择最新版本的进行下载：
3.安装graphviz软件
下载成功后，点击下载好的.exe文件进行安装，一路默认到达下图步骤即可。
选择Do not add Graphviz to the system PATH（我们后续手动添加，防止环境变量混乱）
切记安装路径！
安装目录根据个人喜好进行选择
接下来默认安装即可。
4.配置环境变量
（1）用户变量
（Win10）右键此电脑——>属性——>高级系统设置——>环境变量——>xxx的用户变量——>双击Path——>新建——>粘贴上文所提到的安装路径下的bin（例：D:\Graphviz\bin）——>点击“确定”
（2）系统变量
（Win10）右键此电脑——>属性——>高级系统设置——>环境变量——>系统变量——>双击Path——>新建——>粘贴上文所提到的安装路径下的bin（例：D:\Graphviz\bin\dot.exe）——>点击“确定”
⚠⚠⚠若Path中首行存在相对路径，如：%JAVA_HOME%等，在末尾路径添加英文分号，再粘贴安装目录即可。
（3）检测环境变量是否配置成功
按下win+R，输入cmd回车，输入
dot -version
若出现如下信息，则证明安装成功
5.运行代码
接下来就可以正常运行代码了，需要导入第三方库
import graphviz
========================
https://viper3.top/534/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！业务分析与描述
网络缩小了我们的世界，其发展的迅速带动了人与人的交流，于是像论坛这种交流平台应运而生。然而，网络的应用是离不开底层的数据库支持的，一个良好的数据库系统是网络高效运行的前提。一个专业、针对型高校论坛（RFZF Learing-更具针对性的高校家园），因此为RFZF论坛重新设计一个数据库，对本论坛进行数据存储并进行分析。
数据库概念结构设计
ER图
数据库逻辑结构设计
转换规则
用户（用户编号，用户账户名，用户密码，用户身份，用户性别，用户年龄，用户昵称，用户邮箱，用户手机号，用户IP地址，用户等级，会员等级，用户收藏，用户文章数量，用户余额，注册时间，注销时间）
文章（文章编号，文章名，文章字数，文章作者，标签名，所属分类，最后更新时间）
分类（分类编号，分类名，分类包含文章数量，父级分类）
评论（评论编号，评论内容，评论用户，评论时间，评论文章编号，评论回复）
页面（页面编号，页面名称，创建用户，包含字数，父级页面，最后更新时间）
标签（标签编号，标签名，引用文章）
发送邮件（邮件编号，邮件主题，邮件内容，收件人邮箱，发送时间）
订单（订单编号，用户昵称，订单时间，订单状态）
订单明细（订单编号，商品编号，商品数量，单价，折扣）
商品（商品编号，商品名称，供应商编号，单价，库存）
供应商（供应商编号，用户身份，用户账户名）
数据库表设计
描述
表名：User；该表用于存储有关用户的一切信息，实现对用户信息的增删改等管理。
表名：Posts；该表用于存储论坛内文章的信息。
表名：Category；该表用于存储网页的分类。
表名：Comments；该表用于存储网站内用户的评论信息。
表名：Pages；该表用于存储论坛网站的页面信息。
表名：Tags；该表用于存储论坛文章的标签信息。
表名：Smtp；该表用于存储网站发送至用户的邮件信息。
表名：Orders；该表用于存储论坛的订单信息。
表名：OrderDetails；该表用于存储论坛的订单明细。详细记录一个订单如果购买多个商品，则会针对性记录商品名、商品单价、折扣等信息。
表名：Products；用来存储论坛的CB库存、付费文章、源码等信息。
表名：Suppliers：用来存储供应商的信息。
表结构
User（用户表）
数据定义语言：
CREATE TABLE `User`  (
  `uNo` int(255) NOT NULL AUTO_INCREMENT COMMENT '用户编号',
  `uAc` varchar(16) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '用户账户',
  `uPw` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '用户密码',
  `uId` varchar(6) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '用户身份',
  `uSex` enum('男','女') CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '男' COMMENT '用户性别',
  `uAge` int(255) UNSIGNED NOT NULL COMMENT '用户年龄',
  `uName` varchar(25) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '账户已注销' COMMENT '用户昵称',
  `uEmail` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '用户邮箱',
  `uPhone` int(11) UNSIGNED NOT NULL COMMENT '用户手机号',
  `uIp` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '用户IP地址',
  `uLevel` int(255) UNSIGNED NULL DEFAULT NULL COMMENT '用户等级',
  `uVip` enum('普通会员','N会员','R会员') CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '普通会员' COMMENT '会员等级',
  `uCol` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL COMMENT '用户收藏',
  `uPostQt` int(255) NULL DEFAULT NULL COMMENT '用户文章数量',
  `uBanlance` decimal(16, 2) UNSIGNED NULL DEFAULT NULL COMMENT '用户余额',
  `rTime` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '注册时间',
  `Ltime` datetime NULL DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '注销时间',
  PRIMARY KEY (`uNo`) USING BTREE,
  UNIQUE INDEX `用户账户名`(`uAc`) USING BTREE,
  UNIQUE INDEX `用户手机号`(`uPhone`) USING BTREE,
  UNIQUE INDEX `用户邮箱`(`uEmail`) USING BTREE,
  INDEX `uName`(`uName`) USING BTREE,
  INDEX `uId`(`uId`) USING BTREE
)
序号字段名类型含义备注1uNoint(255)用户编号主键，自增2uAcvarchar(12)用户账户名非空，唯一3uPwvarchar(128)用户密码非空4uIdvarchar(6)用户身份非空5uSexenum(“男”,”女”)用户性别默认为男，非空6uAgeint(255)，unsigned用户年龄非空7uNamevarchar(25)用户昵称默认为账户已注销，非空8uEmailvarchar(255)用户邮箱非空，唯一9uPhoneint(11)，unsigned用户手机号非空，唯一10uIpvarchar(255)用户IP地址11uLevelint(255)，unsigned用户等级12uVipenum(“普通会员”,”N会员”,”R会员”)会员等级默认为普通会员，非空13uColtext用户收藏14uPostint(255)用户文章数量15uBanlancedecimal(16,2),unsigned用户余额16rTimedatetime注册时间非空17LTimedatetime注销时间
Posts（文章表）：
数据定义语言：
CREATE TABLE `Posts`  (
  `pNo` int(255) NOT NULL AUTO_INCREMENT COMMENT '文章编号',
  `pName` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '文章名',
  `uName` varchar(25) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '文章作者',
  `pNow` bigint(255) NOT NULL COMMENT '文章字数',
  `tName` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '标签名',
  `cName` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '所属分类',
  `lastTime` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '最后更新时间',
  PRIMARY KEY (`pNo`) USING BTREE,
  INDEX `所属分类`(`cName`) USING BTREE,
  INDEX `标签名`(`tName`) USING BTREE,
  INDEX `文章作者`(`uName`) USING BTREE,
  CONSTRAINT `所属分类` FOREIGN KEY (`cName`) REFERENCES `Category` (`cName`) ON DELETE SET NULL ON UPDATE SET NULL,
  CONSTRAINT `文章作者` FOREIGN KEY (`uName`) REFERENCES `User` (`uName`) ON DELETE SET NULL ON UPDATE SET NULL,
  CONSTRAINT `标签名` FOREIGN KEY (`tName`) REFERENCES `Tags` (`tName`) ON DELETE SET NULL ON UPDATE SET NULL
)
序号字段名类型含义备注1pNoint(255)文章编号主键，自增2pNamevarchar(255)文章名非空3uNamevarchar(255)文章作者外键，参照User(uName)，级联删除SET NULL，级联更新SET NULL4pNowbigint(255)文章字数非空5tNamevarchar(255)标签名外键，参照Tags(tName)，级联删除SET NULL，级联更新SET NULL6cNamevarchar(255)所属分类外键，参照Category(cName)，级联删除SET NULL，级联更新SET NULL7lastTimedatetime最后更新时间非空
Category（分类表）：
数据定义语言：
CREATE TABLE `Category`  (
  `cNo` int(255) NOT NULL AUTO_INCREMENT COMMENT '分类编号',
  `cName` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '分类名',
  `cNoai` int(255) UNSIGNED NULL DEFAULT 0 COMMENT '分类包含文章数量',
  `cParents` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '父级分类',
  PRIMARY KEY (`cNo`) USING BTREE,
  UNIQUE INDEX `分类名`(`cName`) USING BTREE
)
序号字段名类型含义备注1cNoint(255)分类编号主键，自增2cNamevarchar(255)分类名非空3cNoaiint(255)分类包含文章数量4cParentvarchar(255)父级分类
Comment（评论表）：
数据定义语言：
CREATE TABLE `Comments`  (
  `cNo` int(255) NOT NULL AUTO_INCREMENT COMMENT '评论编号',
  `cContent` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '评论内容',
  `uName` varchar(25) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '评论用户',
  `cTime` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '评论时间',
  `pNo` int(255) NULL DEFAULT NULL COMMENT '评论文章编号',
  `cConContent` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '评论回复',
  PRIMARY KEY (`cNo`) USING BTREE,
  INDEX `评论用户`(`uName`) USING BTREE,
  INDEX `评论文章编号`(`pNo`) USING BTREE,
  CONSTRAINT `评论文章编号` FOREIGN KEY (`pNo`) REFERENCES `Posts` (`pNo`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `评论用户` FOREIGN KEY (`uName`) REFERENCES `User` (`uName`) ON DELETE SET NULL ON UPDATE CASCADE
)
序号字段名类型含义备注1cNoint(255)评论编号主键，自增2cContentvarchar(255)评论内容非空3uNamevarchar(25)评论用户外键，参照User(uName)，级联删除SET NULL，级联更新CASCADE4cTimedatetime评论时间非空5pNoint(255)评论文章编号外键，参照Posts(pNo)，级联删除SET NULL，级联更新SET NULL6cConContentvarchar(255)评论回复默认为NULL
Pages（页面表）
数据定义语言：
CREATE TABLE `Pages`  (
  `pNo` int(255) NOT NULL AUTO_INCREMENT COMMENT '页面编号',
  `pName` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '页面名称',
  `uName` varchar(25) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '创建用户',
  `pParent` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '父级页面',
  `pNow` bigint(255) NULL DEFAULT 0 COMMENT '包含字数',
  `pUptime` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '最后更新时间',
  PRIMARY KEY (`pNo`) USING BTREE,
  UNIQUE INDEX `页面名称`(`pName`) USING BTREE,
  INDEX `创建用户`(`uName`) USING BTREE,
  CONSTRAINT `创建用户` FOREIGN KEY (`uName`) REFERENCES `User` (`uName`) ON DELETE SET NULL ON UPDATE CASCADE
)
序号字段名类型含义备注1pNoint(255)页面编号主键，自增2pNamevarchar(255)页面名称非空，唯一3uNamevarchar(25)创建用户外键，参照User(uName)，级联删除SET NULL，级联更新CASCADE4pParentvarchar(255)父级页面5pNowbigint(255)包含数字6pUptimedatetime最后更新时间非空
Tags（标签表）：
数据定义语言：
CREATE TABLE `Tags`  (
  `tID` int(255) NOT NULL AUTO_INCREMENT COMMENT '标签编号',
  `tName` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '标签名',
  `tCite` text CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '引用文章',
  PRIMARY KEY (`tID`) USING BTREE,
  UNIQUE INDEX `标签名`(`tName`) USING BTREE
)
序号字段名类型含义备注1tIDint(255)标签编号主键，自增2tNamevarchar(255)标签名非空，唯一3tCitetext引用文章非空
Smtp（发送邮件）：
数据定义语言：
CREATE TABLE `Smtp`  (
  `sID` int(255) NOT NULL AUTO_INCREMENT COMMENT '邮件编号',
  `sTimestamp` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '发送时间',
  `sTo` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '收件人邮箱',
  `sTheme` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '邮件主题',
  `sMessage` text CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '邮件内容',
  PRIMARY KEY (`sID`) USING BTREE,
  INDEX `收件人邮箱`(`sTo`) USING BTREE,
  CONSTRAINT `收件人邮箱` FOREIGN KEY (`sTo`) REFERENCES `User` (`uEmail`) ON DELETE CASCADE ON UPDATE CASCADE
)
序号字段名类型含义备注1sIDint(255)邮件编号主键，自增2sTimestampdatetime发送时间非空3sTOvarchar(255)收件人邮箱外键，参照User（uEmail），级联删除更新CASCADE4sThemevarchar(255)邮件主题默认为空
Orders（订单表）：
数据定义语言：
CREATE TABLE `Orders`  (
  `OrderID` int(255) NOT NULL AUTO_INCREMENT COMMENT '订单编号',
  `uName` varchar(25) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '用户昵称',
  `OrderDate` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '订单时间',
  `Status` enum('1','0') CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '0' COMMENT '订单状态',
  PRIMARY KEY (`OrderID`) USING BTREE,
  UNIQUE INDEX `订单编号`(`OrderID`) USING BTREE,
  INDEX `用户昵称`(`uName`) USING BTREE,
  CONSTRAINT `用户昵称` FOREIGN KEY (`uName`) REFERENCES `User` (`uName`) ON DELETE SET NULL ON UPDATE CASCADE
)
序号字段名类型含义备注1OrderIDint(255)订单编号主键，自增2uNamevarchar(25)用户昵称外键，参照User(uName)，级联删除SET NULL，级联更新CASCADE3OrderDatedatetime订单时间非空4Statusenum（‘0’，‘1’）订单状态默认为0，非空订单状态
OrderDetails（订单明细表）：
数据定义语言：
CREATE TABLE `OrderDetails`  (
  `OrderID` int(255) NULL DEFAULT NULL COMMENT '订单编号',
  `ProductID` int(255) NULL DEFAULT NULL COMMENT '商品编号',
  `Quantity` int(255) NOT NULL COMMENT '商品数量',
  `UnitPrice` decimal(6, 2) UNSIGNED NULL DEFAULT NULL COMMENT '单价',
  `Discount` decimal(3, 2) UNSIGNED ZEROFILL NULL DEFAULT 1.00 COMMENT '折扣',
  INDEX `订单编号`(`OrderID`) USING BTREE,
  INDEX `商品编号`(`ProductID`) USING BTREE,
  INDEX `单价`(`UnitPrice`) USING BTREE,
  CONSTRAINT `单价` FOREIGN KEY (`UnitPrice`) REFERENCES `Products` (`UnitPrice`) ON DELETE SET NULL ON UPDATE CASCADE,
  CONSTRAINT `商品编号` FOREIGN KEY (`ProductID`) REFERENCES `Products` (`ProductID`) ON DELETE SET NULL ON UPDATE CASCADE,
  CONSTRAINT `订单编号` FOREIGN KEY (`OrderID`) REFERENCES `Orders` (`OrderID`) ON DELETE SET NULL ON UPDATE CASCADE
)
序号字段名类型含义备注1OrderIDint(255)订单编号外键，参照Orders（OrderID），级联删除SET NULL，级联更新CASCADE，默认为NULL2ProductIDint(255)商品编号外键，参照Products（ProductID），级联删除SET NULL，级联更新CASCADE，默认为NULL3Quantityint(255)商品数量非空4UnitPricedecimal（6,2），unsigned单价外键，参照Products（UnitPrice)，级联删除SET NULL，级联更新CASCADE，默认为NULL5Discountdecimal（3，2），unsigned折扣默认为1.00
Products（商品表）：
数据定义语言：
CREATE TABLE `Products`  (
  `ProductID` int(255) NOT NULL AUTO_INCREMENT COMMENT '商品编号',
  `sNo` int(255) NULL DEFAULT NULL COMMENT '供应商编号',
  `ProductName` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '商品名称',
  `UnitInStock` int(255) UNSIGNED NULL DEFAULT NULL COMMENT '库存',
  `UnitPrice` decimal(6, 2) UNSIGNED NULL DEFAULT NULL COMMENT '单价',
  PRIMARY KEY (`ProductID`) USING BTREE,
  INDEX `UnitPrice`(`UnitPrice`) USING BTREE,
  INDEX `sNo`(`sNo`) USING BTREE,
  CONSTRAINT `sNo` FOREIGN KEY (`sNo`) REFERENCES `Suppliers` (`sNo`) ON DELETE SET NULL ON UPDATE CASCADE
)
序号字段名类型含义备注1ProductIDint(255)商品编号主键，自增2sNoint(255)供应商编号外键，参照Suppliers（sNo）级联删除SET NULL，级联更新CASCADE，默认为NULL3ProductNamevarchar(255)商品名称默认为NULL4UnitInStockint(255),unsigned库存默认为NULL5UnitPricedecimal(6,2),unsigned单价默认为NULL
Suppliers（供应商表）：
数据定义语言：
CREATE TABLE `Suppliers`  (
  `sNo` int(255) NOT NULL AUTO_INCREMENT COMMENT '供应商编号',
  `uAc` varchar(16) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '用户账户名',
  `uId` varchar(6) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '用户身份',
  PRIMARY KEY (`sNo`) USING BTREE,
  INDEX `用户账户`(`uAc`) USING BTREE,
  INDEX `用户身份`(`uId`) USING BTREE,
  CONSTRAINT `用户账户` FOREIGN KEY (`uAc`) REFERENCES `User` (`uAc`) ON DELETE SET NULL ON UPDATE CASCADE,
  CONSTRAINT `用户身份` FOREIGN KEY (`uId`) REFERENCES `User` (`uId`) ON DELETE SET NULL ON UPDATE CASCADE
)
序号字段名类型含义备注1sNoint(255)供应商编号主键，自增2uAcvarchar(16)用户账户名外键，参照User（uAc），级联删除SET NULL，级联更新CASCADE，默认为NULL3uIdvarchar(6)用户身份外键，参照User（uId）级联删除SET NULL，级联更新CASCADE，默认为NULL
触发器
OrderDetails（订单明细）：
①使用触发器实现检查约束，确保插入订单明细时，其折扣在[0,1]范围内。如果小于0，则为0；如果大于1，则为1。
DELIMITER $$
CREATE TRIGGER od_insert_before_trigger BEFORE INSERT ON OrderDetails
FOR EACH ROW
BEGIN
    IF NEW.discount<0 THEN SET NEW.discount=0;
    ELSEIF NEW.discount>1 THEN SET NEW.discount=1;
END IF;
END
$$
②使用触发器实现检查约束，确保更新订单明细中的记录时其折扣在[0,1]范围内。如果不在该范围内，则为原来的值。
DELIMITER $$
CREATE TRIGGER od_update_ before_trigger BEFORE UPDATE ON OrderDetails
FOR EACH ROW
BEGIN
    IF NEW.discount<0 OR NEW.discount>1 THEN
    SET NEW.discount=OLD.discount;
END IF;
END
$$
Orders（订单表）：
①使用触发器实现关联数据修改，当订单状态由0变为1时，变更对应商品的在单数量及库存数量。
DELIMITER $$
CREATE TRIGGER orders_update_before_trigger BEFORE UPDATE ON Orders
FOR EACH ROW
BEGIN
    IF NEW.Status=1 AND OLD.Status=0 THEN
    UPDATE Products INNER JOIN OrderDetails ON 
    Products.ProductID=OrderDetails.ProductID
    SET UnitsInStock=UnitsInStock-Quantity,
    UnitsOnOrder=UnitsOnOrder-Quantity
    WHERE OrderDetails.OrderID=NEW.OrderID;
END IF;
END
$$
规范化分析
User（用户表）：
（1）F={用户编号->用户账户名
用户编号->用户密码
用户编号->用户身份
用户编号->用户性别
用户编号->用户年龄
用户编号->用户昵称
用户编号->用户手机号
用户编号->用户邮箱
用户编号->用户IP地址
用户编号->用户等级
用户编号->会员等级
用户编号->用户收藏
用户编号->用户文章数量
用户编号->用户余额
用户编号->注册时间
用户编号->注销时间
用户账户名->用户编号
用户账户名->用户密码
用户账户名->用户身份
用户账户名->用户性别
用户账户名->用户年龄
用户账户名->用户昵称
用户账户名->用户手机号
用户账户名->用户邮箱
用户账户名->用户IP地址
用户账户名->用户等级
用户账户名->会员等级
用户账户名->用户收藏
用户账户名->用户文章数量
用户账户名->用户余额
用户账户名->注册时间
用户账户名->注销时间
用户手机号->用户编号
用户手机号->用户账户名
用户手机号->用户密码
用户手机号->用户身份
用户手机号->用户性别
用户手机号->用户年龄
用户手机号->用户昵称
用户手机号->用户邮箱
用户手机号->用户IP地址
用户手机号->用户等级
用户手机号->会员等级
用户手机号->用户收藏
用户手机号->用户文章数量
用户手机号->用户余额
用户手机号->注册时间
用户手机号->注销时间
用户邮箱->用户编号
用户邮箱->用户账户名
用户邮箱->用户密码
用户邮箱->用户身份
用户邮箱->用户性别
用户邮箱->用户年龄
用户邮箱->用户昵称
用户邮箱->用户手机号
用户邮箱->用户IP地址
用户邮箱->用户等级
用户邮箱->会员等级
用户邮箱->用户收藏
用户邮箱->用户文章数量
用户邮箱->用户余额
用户邮箱->注册时间
用户邮箱->注销时间}
（2）码：用户编号、用户账户名、用户手机号、用户邮箱
主属性：用户编号、用户账户名、用户手机号、用户邮箱
（3）非主属性：用户密码、用户身份、用户性别、用户年龄、用户昵称、用户手机号、用户IP地址、用户等级、会员等级、用户收藏、用户文章数量、用户余额、注册时间、注销时间
（4）用户关系模式中每一个非主属性既不部分依赖于码也不传递依赖于码，所有非主属性对每一个码都完全函数依赖，所有主属性对每个不包含它的码都完全函数依赖，没有任何属性完全函数依赖于非码的任何一组属性。因此用户关系模式属于BCNF。
Posts（文章表）：
（1）F={文章编号->文章名
文章编号->文章作者
文章编号->所属分类
文章编号->标签名
文章编号->文章字数
 文章编号->最后更新时间}
（2）码：文章编号
 主属性：文章编号
（3）非主属性：文章名，文章作者，所属分类，文章字数，最后更新时间
（4）文章关系模式中每一个非主属性既不部分依赖于码也不传递依赖于码，所有非主属性对每一个码都完全函数依赖，所有主属性对每个不包含它的码都完全函数依赖，没有任何属性完全函数依赖于非码的任何一组属性。因此文章关系模式属于BCNF。
Category（分类表）：
（1）F={分类编号->分类名
 分类编号->分类包含文章数量
分类编号->父级分类}
（2）码：分类编号
主属性：分类编号
（3）非主属性：分类名，分类包含文章数量，父级分类
（4）分类关系模式中每一个非主属性既不部分依赖于码也不传递依赖于码，所有非主属性对每一个码都完全函数依赖，所有主属性对每个不包含它的码都完全函数依赖，没有任何属性完全函数依赖于非码的任何一组属性。因此分类关系模式属于BCNF。
Comments（评论表）：
（1）F={评论编号->评论内容
 评论编号->评论用户
 评论编号->评论时间
 评论编号->评论文章编号
 评论编号->评论回复}
（2）码：评论编号
主属性：评论编号
（3）非主属性：评论内容，评论用户，评论时间，评论文章编号，评论回复
（4）评论关系模式中每一个非主属性既不部分依赖于码也不传递依赖于码，所有非主属性对每一个码都完全函数依赖，所有主属性对每个不包含它的码都完全函数依赖，没有任何属性完全函数依赖于非码的任何一组属性。因此评论关系模式属于BCNF。
Pages（页面表）：
（1）F={页面编号->页面名称
 页面编号->创建用户
 页面编号->包含字数
 页面编号->父级页面
 页面编号->最后更新时间
页面名称->页面编号
页面名称->创建用户
页面名称->包含字数
页面名称->父级页面
页面名称->最后更新时间}
（2）码：页面编号，页面名称
主属性：页面编号，页面名称
（3）非主属性：创建用户，包含字数，父级页面，最后更新时间
（4）页面关系模式中每一个非主属性既不部分依赖于码也不传递依赖于码，所有非主属性对每一个码都完全函数依赖，所有主属性对每个不包含它的码都完全函数依赖，没有任何属性完全函数依赖于非码的任何一组属性。因此页面关系模式属于BCNF。
Tags（标签表）：
（1）F={标签编号->标签名
标签编号->引用文章
标签名->标签编号
标签名->引用文章}
（2）码：标签编号，标签名
主属性：标签编号，标签名
（3）非主属性：引用文章
（4）标签关系模式中每一个非主属性既不部分依赖于码也不传递依赖于码，所有非主属性对每一个码都完全函数依赖，所有主属性对每个不包含它的码都完全函数依赖，没有任何属性完全函数依赖于非码的任何一组属性。因此标签关系模式属于BCNF。
Smtp（发送邮件）：
（1）F={邮件编号->邮件主题
 邮件编号->邮件内容
 邮件编号->收件人邮箱
 邮件编号->发送时间}
（2）码：邮件编号
主属性：邮件编号
（3）非主属性：邮件主题，邮件内容，收件人邮箱，发送时间
（4）发送邮件关系模式中每一个非主属性既不部分依赖于码也不传递依赖于码，所有非主属性对每一个码都完全函数依赖，所有主属性对每个不包含它的码都完全函数依赖，没有任何属性完全函数依赖于非码的任何一组属性。因此发送邮件关系模式属于BCNF。
Orders（订单表）：
（1）F={订单编号->用户昵称
 订单编号->订单时间
 订单编号->订单状态}
（2）码：订单编号
主属性：订单编号
（3）非主属性：用户昵称，订单时间，订单状态
（4）订单关系模式中每一个非主属性既不部分依赖于码也不传递依赖于码，所有非主属性对每一个码都完全函数依赖，所有主属性对每个不包含它的码都完全函数依赖，没有任何属性完全函数依赖于非码的任何一组属性。因此订单关系模式属于BCNF。
OrderDetails（订单明细）：
（1）F={商品编号->单价
订单编号->折扣
 （订单编号，商品编号）->商品数量}
（2）码：（商品编号，订单编号）
主属性：商品编号，订单编号
（3）非主属性：单价，折扣，商品数量
（4）订单明细关系模式种既不存在非主属性对码的部分函数依赖，也不存在非主属性对码的传递函数依赖，因此订单明细关系模式属于3NF。考虑到数据冗余情况，因此不将该关系模式分解为BCNF。
Products（商品）：
（1）F={商品编号->商品名称
商品编号->供应商编号
商品编号->单价
商品编号->库存}
（2）码：商品编号
主属性：商品编号
（3）非主属性：商品名称，供应商编号，单价，库存
（4）商品关系模式中每一个非主属性既不部分依赖于码也不传递依赖于码，所有非主属性对每一个码都完全函数依赖，所有主属性对每个不包含它的码都完全函数依赖，没有任何属性完全函数依赖于非码的任何一组属性。因此商品关系模式属于BCNF。
Suppliers（供应商表）：
（1）F={供应商编号->用户身份
用户身份->用户账户名}
（2）码：供应商编号
 主属性：供应商编号
（3）非主属性：用户身份，用户账户名
（4）供应商关系模式由于非主属性存在对码的传递函数依赖，所以供应商关系模式不属于3NF，但供应商关系模式不存在对码的部分函数依赖，所以供应商关系模式属于2NF。
若将供应商关系模式分解为3NF，结果为：供应商（供应商编号，用户账户名）；供应商（供应商编号、用户身份），造成了不必要的数据冗余，因此不将该关系模式分解。
总结
最终在可视化工具Navicat中预览了所有数据库表。
Navicat16工具下载与使用：最新Navicat Premium 16下载与安装教程 – RFZF Learning 
========================
https://viper3.top/313/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！什么是WP Mail SMTP？为什么需要它发送WordPress电子邮件？
WP Mail SMTP是最好的WordPress SMTP插件，它使您可以使用安全的邮件传输协议或SMTP轻松发送WordPress电子邮件。 在本文中，我们将向您展示如何轻松地使用任何主机设置WP Mail SMTP。
WP Mail SMTP是WordPress插件，可让您使用SMTP服务器发送WordPress电子邮件。 这样可以确保您的WordPress电子邮件是使用标准邮件协议发送的。
设置WordPress网站后，您可能会注意到您没有收到来自WordPress的任何电子邮件。 这包括WordPress通知电子邮件和WordPress联系人表单插件发送的电子邮件。
原因是WordPress使用PHPmail()函数发送电子邮件。 大多数WordPress托管公司没有正确配置它，有些只是禁用它以防止滥用。
解决此问题的最简单方法是使用SMTP发送WordPress电子邮件。
SMTP是安全的邮件传输协议，它几乎是发送电子邮件的标准方法。 它要求您登录到邮件服务器以发送电子邮件，以防止滥用托管服务器并提高电子邮件的可传递性。
大多数WordPress托管公司都提供免费的企业电子邮件地址，您可以将其与自己的域名一起使用。 我们建议为您的WordPress网站设置一个单独的电子邮件地址。 它可以是诸如support@example.com或info@example.com之类的任何内容。
创建电子邮件地址后，您可以使用它发送WordPress电子邮件。 您仍然需要告诉WordPress如何与您的邮件服务器连接。
这是WP Mail SMTP插件的来源。它允许您通过输入SMTP凭据通过SMTP发送WordPress电子邮件。
WP Mail SMTP是最流行的WordPress SMTP解决方案(当前有超过一百万个网站使用)。 它由与WPForms相同的团队维护 。
您需要做的第一件事是安装并激活WP Mail SMTP插件。 有关更多详细信息，请参阅有关如何安装WordPress插件的分步指南。
激活后，您需要访问设置»WP Mail SMTP页面以配置插件设置。
您需要输入SMTP设置才能使用WP Mail SMTP。 无论托管公司如何，设置的第一部分都是相似的。 它包括以下设置：
From Email– This is the email address which will be used to send all WordPress emails.来自电子邮件–这是将用于发送所有WordPress电子邮件的电子邮件地址。
From Name– This name will be used to send emails. We recommend using your website’s title as from name.发件人名称-此名称将用于发送电子邮件。 我们建议您使用网站标题作为名称。
Mailer– You need to select ‘Other SMTP’ here as you will be sending emails using your hosts SMTP serverMailer–您需要在此处选择“其他SMTP”，因为您将使用主机SMTP服务器发送电子邮件
Return Path– Check this box to receive delivery notifications or bounced messages.返回路径–选中此框以接收传递通知或退回邮件。
注意：如果要使用第三方邮件，则可以按照本指南通过Gmail SMTP发送WordPress电子邮件。 我们还为Sendinblue SMTP设置提供了类似的指南。
如果要继续使用主机，则需要选择其他SMTP，然后输入托管公司提供的SMTP服务器设置。
SMTP Host– This is the SMTP host address provided by your hosting company.SMTP主机-这是您的托管公司提供的SMTP主机地址。
Encryption– The encryption method used by your mail server to send emails. Usually it is TLS.加密–邮件服务器用来发送电子邮件的加密方法。 通常是TLS。
SMTP Port– This is the port used by outgoing mail server.SMTP端口–这是传出邮件服务器使用的端口。
Auto TLS– This setting should be set to On自动TLS–此设置应设置为“开”
Authentication– Needs to be On身份验证–需要开启
SMTP Username– This is usually the email address you are using to send emailsSMTP用户名-这通常是您用于发送电子邮件的电子邮件地址
SMTP Password– This is the password for the email account you are using to send emails. We don’t recommend saving SMTP password here. Instead, you nedd to store your password inSMTP密码–这是您用于发送电子邮件的电子邮件帐户的密码。 我们不建议在此处保存SMTP密码。 相反，您需要将密码存储在wp-config.php file.wp-config.php文件中。
这些设置是连接任何SMTP服务器所必需的。 但是，它们的价值可能从一家WordPress托管公司到另一家WordPress托管公司不同。
让我们看看如何与不同的托管公司一起设置WP Mail SMTP插件。
使用第三方电子邮件服务设置WP Mail SMTP
一些托管的WordPress托管公司不提供电子邮件服务作为其托管计划的一部分。 在这种情况下，您将需要使用第三方电子邮件服务来通过SMTP发送WordPress电子邮件。
使用SMTP发送WordPress电子邮件的最佳方法是使用G Suite(以前称为Google Apps for Work)。 它使您可以创建专业的企业电子邮件地址，并将现有的域名与Gmail，日历，Google云端硬盘等流行的Google应用程序结合使用。
WP Mail SMTP允许您轻松配置WordPress以使用Gmail服务器发送电子邮件。 这包括G Suite以及您的常规Gmail帐户。 有关详细说明，请参阅有关如何使用Gmail SMTP服务器发送WordPress电子邮件的分步指南。
您还可以使用MailGun发送WordPress电子邮件。 有关详细信息，请参阅本指南，了解如何通过MailGun发送WordPress电子邮件。
WP Mail SMTP还允许您选择SendGrid作为邮件程序。 您只需要输入可以在SendGrid帐户下找到的API密钥即可。
我们希望本文能帮助您学习如何与任何主机一起设置WP Mail SMTP。 您可能还想查看我们的指南，以了解为什么不应该使用WordPress发送时事通讯电子邮件的原因。
========================
https://viper3.top/828/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！1.配置Spring boot运行环境
1.1创建项目
（1）在IDEA中新建项目，生成器选择Spring Initializr。其中语言选择Java，类型选择Maven，组与工件设置好后，名称与软件包名称随之变化。JDK版本大于等于Java版本，点击下一步。
（2）Spring Boot版本默认为2.7.5，依赖项：Developer Tools选择Lombok，Web选择Spring Web，NoSQL选择Spring Data MongoDB，点击创建。
1.2导入并配置Maven
（1）IDEA会自动同步该项目的依赖项与插件并导入Maven，等待即可。
（2）进入IDEA设置，依次进入“构建、执行、部署——构建工具——Maven”，设置Maven主路径、用户设置文件、本地仓库。
（3）在pom.xml中的dependencies标签下追加以下内容：
<dependency>
    <groupId>cn.hutool</groupId>
    <artifactId>hutool-all</artifactId>
    <version>5.6.3</version>
</dependency>
（4）在pom.xml中的build标签下有plugin标签，此处可能会报错，可在artifactId标签后加入version标签，填入2.7.5，点击右上角的变更按钮，即可完成插件同步。
1.3配置MongoDB
（1）在项目根目录下的src目录下存在resources文件夹，双击文件夹下的application.properties文件，输入
spring.data.mongodb.uri = mongodb://localhost:27017/bigdatadb
（2）到此，Spring Boot的运行环境已经搭建完成，下面将进行前后端项目的部署与页面实现。
2.实现订单添加功能
2.1Order类
package cn.bipt.bigdata2022.pojo;
import com.fasterxml.jackson.annotation.JsonFormat;
import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;
import java.io.Serializable;
import java.util.Date;
import java.util.List;
/**
* 订单
*/
@Data
@NoArgsConstructor
@AllArgsConstructor
public class Order implements Serializable {
    private String id; // 订单编号
    private String status; // 订单状态
    @JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss", timezone = "GMT+8")
    private Date orderTime; // 下单时间
    private String shipper; // 发货人
    private String shipperAddress; // 发货人地址
    private String shipperPhone; // 发货人电话
    @JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss", timezone = "GMT+8")
    private Date shipTime; // 发货时间
    private String receiver; // 收货人
    private String receiverAddress; // 收货人地址
    private String receiverPhone; // 收货人电话
    private List<Logistics> logistics; // 物流信息
}
2.2Logistics类
package cn.bipt.bigdata2022.pojo;
import com.fasterxml.jackson.annotation.JsonFormat;
import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;
import java.io.Serializable;
import java.util.Date;
/**
* 物流
*/
@Data
@NoArgsConstructor
@AllArgsConstructor
public class Logistics implements Serializable {
    private String orderId; // 订单编号
    private String operation; // 操作名称
    private String operator; // 操作员
    private String phone; // 操作员电话
    @JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss", timezone = "GMT+8")
    private Date operationTime; // 操作时间
    private String address; // 操作地址
    private String details; // 详细信息
}
2.3OrderService类
package cn.bipt.bigdata2022.service;
import cn.hutool.core.util.IdUtil;
import cn.bipt.bigdata2022.pojo.Logistics;
import cn.bipt.bigdata2022.pojo.Order;
import com.mongodb.client.result.DeleteResult;
import org.springframework.data.mongodb.core.MongoTemplate;
import org.springframework.data.mongodb.core.query.Criteria;
import org.springframework.data.mongodb.core.query.Query;
import org.springframework.data.mongodb.core.query.Update;
import org.springframework.stereotype.Service;
import javax.annotation.Resource;
import java.util.Date;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
@Service
public class OrderService {
    @Resource
    private MongoTemplate mongoTemplate;
    /**
    * 添加订单至 MongoDB
    *
    * @param order
    */
    public void addOrder(Order order) {
    // 订单编号根据雪花算法生成
    order.setId(IdUtil.getSnowflake(1, 1).nextIdStr());
    // 设置订单状态
    order.setStatus("已下单");
    // 设置下单时间
    order.setOrderTime(new Date());
    // 设置发货时间
    order.setShipTime(new Date());
    // 添加订单至 MongoDB
    mongoTemplate.insert(order, "order");
    }
    /**
    * 更新订单信息
    * 追加物流信息
    *
    * @param logistics
    */
    public void updateOrderAndAddLogistics(Logistics logistics) {
   // 获取操作名称
   String status = logistics.getOperation();
   // 设置操作时间
   logistics.setOperationTime(new Date());
   // 初始化 Query 对象，根据订单编号查询
   Query query = new Query(Criteria.where("_id").is(logistics.getOrderId()));
   // 初始化 Update 对象
   Update update = new Update();
   // 更新订单状态
   update.set("status", status);
   // 追加物流信息
   update.push("logistics", logistics);
   // 更新订单信息
   mongoTemplate.upsert(query, update, Order.class, "order");
    }
    /**
    * 通过订单编号查询
    *
    * @param id
    * @return
    */
    public Order selectOrderById(String id) {
   // 初始化 Query 对象，根据订单编号查询
   Query query = new Query(Criteria.where("_id").is(id));
   return mongoTemplate.findOne(query, Order.class, "order");
    }
    /**
    * 查询所有订单
    *
    * @return
    */
    public Map<String, Object> selectOrderList() {
   List<Order> list = mongoTemplate.findAll(Order.class, "order");
   Map<String, Object> result = new HashMap<>();
   if (list == null || list.isEmpty()) {
   result.put("code", "400");
   result.put("message", "没有相关订单信息");
   } else {
  result.put("code", "0");
  result.put("count", list.size());
  result.put("data", list);
   }
   return result;
    }
    /**
    * 根据订单编号删除订单记录
    *
    * @param id
    * @return
    */
    public boolean deleteOrderById(String id) {
   // 初始化 Query 对象，根据订单编号查询
   Query query = new Query(Criteria.where("_id").is(id));
   DeleteResult result = mongoTemplate.remove(query, Order.class, "order");
   return result.getDeletedCount() > 0 ? true : false;
    }
}
2.4OrderController类
package cn.bipt.bigdata2022.controllerimport cn.bipt.bigdata2022.pojo.Logistics; import cn.bipt.bigdata2022.pojo.Order; import cn.bipt.bigdata2022.service.OrderService; import org.springframework.web.bind.annotation.*; import javax.annotation.Resource; import java.util.Map; @RestController @RequestMapping("order") public class OrderController {    
@Resource    
private OrderService orderService;    
/**    
* 添加订单至 MongoDB    
*    
* @param order    
* @return    
*/    
@PostMapping("add")    
public String addOrder(Order order) {    
    System.out.println(1);    
   orderService.addOrder(order); return "订单添加成功";    }    
/**    * 更新订单信息    
* 添加物流信息    
*    
* @param logistics    
* @return    
*/    
@PostMapping("update")    
public String updateOrderAndAddLogistics(Logistics logistics) {    orderService.updateOrderAndAddLogistics(logistics);    return "物流添加成功";    
}    
/**    
* 通过订单编号查询    
*    
* @param id    
* @return    
*/    
@GetMapping("{id}")    
public Order selectOrderById(@PathVariable String id) {    
    return orderService.selectOrderById(id);    
}    
/**    
* 查询所有订单    
*    
* @return    
*/    
@GetMapping("list")    
public Map<String, Object> selectOrderList() {    
    return orderService.selectOrderList();    
}    
/**    
* 根据订单编号删除订单记录    
*    
* @param id    
* @return    
*/    
@PostMapping("delete")    
public String deleteById(String id) {    
    orderService.deleteOrderById(id);    
    return "删除成功";    
}}
2.5index.html
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>物流管理系统</title>
  <link crossorigin="anonymous" integrity="sha512-SSF+OBDODWTSIqOivYBOyOKQ93PBDevipJEUEWtkUbTt4v34rmgPcCXcBMolxZIJcuobcdqmYJlonjUBEbOzNw==" href="https://lib.baomitu.com/layui/2.7.6/css/layui.css" rel="stylesheet">
</head>
<body>
<div class="layui-layout layui-layout-admin">
  <div class="layui-header">
    <div class="layui-logo layui-hide-xs layui-bg-black">物流管理系统</div>
    <!-- 头部区域（可配合layui 已有的水平导航） -->
    <ul class="layui-nav layui-layout-left">
 <!-- 移动端显示 -->
 <li class="layui-nav-item layui-show-xs-inline-block layui-hide-sm" lay-header-event="menuLeft">
   <i class="layui-icon layui-icon-spread-left"></i>
 </li>
 <li class="layui-nav-item layui-hide-xs"><a href="">nav 1</a></li>
 <li class="layui-nav-item layui-hide-xs"><a href="">nav 2</a></li>
 <li class="layui-nav-item layui-hide-xs"><a href="">nav 3</a></li>
 <li class="layui-nav-item">
   <a href="javascript:;">nav groups</a>
   <dl class="layui-nav-child">
<dd><a href="">menu 11</a></dd>
<dd><a href="">menu 22</a></dd>
<dd><a href="">menu 33</a></dd>
   </dl>
 </li>
    </ul>
    <ul class="layui-nav layui-layout-right">
 <li class="layui-nav-item layui-hide layui-show-md-inline-block">
   <a href="javascript:;">
<img src="//tva1.sinaimg.cn/crop.0.0.118.118.180/5db11ff4gw1e77d3nqrv8j203b03cweg.jpg" class="layui-nav-img">
Viper3
   </a>
   <dl class="layui-nav-child">
<dd><a href="">Your Profile</a></dd>
<dd><a href="">Settings</a></dd>
<dd><a href="">Sign out</a></dd>
   </dl>
 </li>
 <li class="layui-nav-item" lay-header-event="menuRight" lay-unselect>
   <a href="javascript:;">
<i class="layui-icon layui-icon-more-vertical"></i>
   </a>
 </li>
    </ul>
  </div>
  <div class="layui-side layui-bg-black">
    <div class="layui-side-scroll">
 <!-- 左侧导航区域（可配合layui已有的垂直导航） -->
 <ul class="layui-nav layui-nav-tree" lay-filter="test">
   <li class="layui-nav-item layui-nav-itemed">
<a class="" href="javascript:;">物流管理</a>
<dl class="layui-nav-child">
  <dd><a href="add-order.html" target="index">添加订单</a></dd>
  <dd><a href="add-logistics.html" target="index">添加物流信息</a></dd>
  <dd><a href="order-manage.html" target="index">订单管理</a></dd>
</dl>
   </li>
 </ul>
    </div>
  </div>
  <div class="layui-body">
    <!-- 内容主体区域 -->
    <iframe width="99%" height="100%" name="index"></iframe>
  </div>
  <div class="layui-footer">
    <!-- 底部固定区域 -->
    底部固定区域
  </div>
</div>
<script crossorigin="anonymous" integrity="sha512-mIKH3M2bRlIyhG4tBEbJ8dn8t8JFlNJU2NXlJePgpQ72CK4jAYsZyCGFcASRGtPBbcAQhz67KTkA1Jw6Kizk9g==" src="https://lib.baomitu.com/layui/2.7.6/layui.js"></script>
<script>
  //JS
  layui.use(['element', 'layer', 'util'], function(){
    var element = layui.element
  ,layer = layui.layer
  ,util = layui.util
  ,$ = layui.$;
    //头部事件
    util.event('lay-header-event', {
 //左侧菜单事件
 menuLeft: function(othis){
   layer.msg('展开左侧菜单的操作', {icon: 0});
 }
 ,menuRight: function(){
   layer.open({
type: 1
,content: '<div style="padding: 15px;">处理右侧面板的操作</div>'
,area: ['260px', '100%']
,offset: 'rt' //右上角
,anim: 5
,shadeClose: true
   });
 }
    });
  });
</script>
</body>
</html>
2.6add-order.html
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>订单添加</title>
    <link crossorigin="anonymous" integrity="sha512-SSF+OBDODWTSIqOivYBOyOKQ93PBDevipJEUEWtkUbTt4v34rmgPcCXcBMolxZIJcuobcdqmYJlonjUBEbOzNw==" href="https://lib.baomitu.com/layui/2.7.6/css/layui.css" rel="stylesheet">
</head>
<body>
<fieldset class="layui-elem-field layui-field-title" style="margin-top: 20px;">
    <legend>订单添加</legend>
</fieldset>
<!--面板-->
<div class="layui-card">
    <div class="layui-card-body">
   <!--表单-->
   <form class="layui-form" action="">
  <div class="layui-form-item">
 <label class="layui-form-label">发货人</label>
 <div class="layui-input-block">
<input type="text" name="shipper" class="layui-input">
 </div>
  </div>
  <div class="layui-form-item">
 <label class="layui-form-label">发货人地址</label>
 <div class="layui-input-block">
<input type="text" name="shipperAddress" class="layui-input">
 </div>
  </div>
  <div class="layui-form-item">
 <label class="layui-form-label">发货人电话</label>
 <div class="layui-input-block">
<input type="text" name="shipperPhone" class="layui-input">
 </div>
  </div>
  <div class="layui-form-item">
 <label class="layui-form-label">收货人</label>
 <div class="layui-input-block">
<input type="text" name="receiver" class="layui-input">
 </div>
  </div>
  <div class="layui-form-item">
 <label class="layui-form-label">收货人地址</label>
 <div class="layui-input-block">
<input type="text" name="receiverAddress" class="layui-input">
 </div>
  </div>
  <div class="layui-form-item">
 <label class="layui-form-label">收货人电话</label>
 <div class="layui-input-block">
<input type="text" name="receiverPhone" class="layui-input">
 </div>
  </div>
  <div class="layui-form-item">
 <div class="layui-input-block">
<button class="layui-btn" lay-submit lay-filter="formDemo">提交</button>
<button type="reset" class="layui-btn layui-btn-primary">重置</button>
 </div>
  </div>
   </form>
    </div>
</div>
<script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script>
<script crossorigin="anonymous" integrity="sha512-mIKH3M2bRlIyhG4tBEbJ8dn8t8JFlNJU2NXlJePgpQ72CK4jAYsZyCGFcASRGtPBbcAQhz67KTkA1Jw6Kizk9g==" src="https://lib.baomitu.com/layui/2.7.6/layui.js"></script>
<script>
    layui.use('form',function(){
   var form=layui.form;
   form.on('submit(formDemo)',function(data){
  $.ajax({
 url:"/order/add",
 type:"POST",
 data:data.field,
 datatype:"JSON",
 success:function(result){
layer.msg(result);
 }
  });
  return false;
   });
    });
</script>
</body>
</html>
2.7add-logistics.html
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>物流添加</title>
    <link rel="stylesheet" href="//lib.baomitu.com/layui/2.6.4/css/layui.min.css">
</head>
<body>
<fieldset class="layui-elem-field layui-field-title" style="margin-top: 20px;">
    <legend>物流添加</legend>
</fieldset>
<!-- 面板 -->
<div class="layui-card">
    <div class="layui-card-body">
   <!-- 表单 -->
   <form class="layui-form" action="">
  <div class="layui-form-item">
 <label class="layui-form-label">订单编号</label>
 <div class="layui-input-block">
<input type="text" name="orderId" class="layui-input">
 </div>
  </div>
  <div class="layui-form-item">
 <label class="layui-form-label">操作名称</label>
 <div class="layui-input-block">
<select name="operation">
    <option value="">请选择</option>
    <option value="已取件">已取件</option>
    <option value="运送中">运送中</option>
    <option value="派送中">派送中</option>
    <option value="已签收">已签收</option>
</select>
 </div>
  </div>
  <div class="layui-form-item">
 <label class="layui-form-label">操作员</label>
 <div class="layui-input-block">
<input type="text" name="operator" class="layui-input">
 </div>
  </div>
  <div class="layui-form-item">
 <label class="layui-form-label">操作员电话</label>
 <div class="layui-input-block">
<input type="text" name="phone" class="layui-input">
 </div>
  </div>
  <div class="layui-form-item">
 <label class="layui-form-label">操作地址</label>
 <div class="layui-input-block">
<input type="text" name="address" class="layui-input">
 </div>
  </div>
  <div class="layui-form-item">
 <label class="layui-form-label">详细信息</label>
 <div class="layui-input-block">
<input type="text" name="details" class="layui-input">
 </div>
  </div>
  <div class="layui-form-item">
 <div class="layui-input-block">
<button class="layui-btn" lay-submit lay-filter="formDemo">提交</button>
<button type="reset" class="layui-btn layui-btn-primary">重置</button>
 </div>
  </div>
   </form>
    </div>
</div>
<script src="//lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script>
<script src="//lib.baomitu.com/layui/2.7.6/layui.min.js"></script>
<script>
    //Demo
    layui.use('form', function () {
   var form = layui.form;
   //监听提交
   form.on('submit(formDemo)', function (data) {
  $.ajax({
 url: "/order/update",
 type: "POST",
 data: data.field,
 dataType: "JSON",
 success: function (result) {
layer.msg(result);
 }
  });
  return false;
   });
    });
</script>
</body>
</html>
2.8order-manage.html
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>订单管理</title>
    <link rel="stylesheet" href="https://lib.baomitu.com/layui/2.7.6/css/layui.min.css">
</head>
<body>
<fieldset class="layui-elem-field layui-field-title" style="margin-top: 20px;">
    <legend>订单管理</legend>
</fieldset>
<!-- 面板 -->
<div class="layui-card">
    <div class="layui-card-body">
   <label class="layui-form-label">订单编号</label>
   <div class="layui-input-inline">
  <input type="text" id="orderId" class="layui-input">
   </div>
   <button onclick="search();" class="layui-btn"><i class="layui-icon">&amp;#xe615;</i></button>
    </div>
</div>
<div style="padding: 20px;margin-bottom: 100px;">
    <!-- 面板 -->
    <div class="layui-col-md12">
   <div class="layui-card">
  <div class="layui-card-header">订单信息</div>
  <div class="layui-card-body" id="order"></div>
   </div>
    </div>
    <!-- 面板 -->
    <div class="layui-col-md12">
   <div class="layui-card">
  <div class="layui-card-header">物流信息</div>
  <div class="layui-card-body">
 <!-- 时间线 -->
 <ul class="layui-timeline" id="logistics">
<!--
<li class="layui-timeline-item">
  <i class="layui-icon layui-timeline-axis">&amp;#xe63f;</i>
  <div class="layui-timeline-content layui-text">
    <div class="layui-timeline-title">过去</div>
  </div>
</li>
-->
 </ul>
  </div>
   </div>
    </div>
    <div class="layui-col-md12">
   <!-- 面板 -->
   <div class="layui-card">
  <div class="layui-card-header">订单列表</div>
  <div class="layui-card-body">
 <!-- 数据表格 -->
 <table id="orderList" lay-filter="orderTable"></table>
  </div>
   </div>
    </div>
</div>
<!-- 头工具栏事件 筛选/导出/打印 -->
<script type="text/html" id="toolbarDemo"></script>
<!-- 行工具事件 -->
<script type="text/html" id="barDemo">
    <a class="layui-btn layui-btn-xs" lay-event="edit">编辑</a>
    <a class="layui-btn layui-btn-danger layui-btn-xs" lay-event="del">删除</a>
</script>
<script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script>
<script src="https://lib.baomitu.com/layui/2.7.6/layui.min.js"></script>
<script>
    // 搜索
    function search() {
   // 订单编号
   var orderId = $("#orderId").val();
   $.ajax({
  url: "/order/" + orderId,
  type: "GET",
  dataType: "JSON",
  // 拼接处理返回结果
  success: function (order) {
 if (order == null || order == undefined || order == "") {
layer.msg("订单不存在");
return;
 }
 // 处理订单信息
 $("#order").append("订单编号：" + orderId + "（" + order["status"] + "）<hr/>")
.append("发货人：" + order["shipper"] + "<br/>")
.append("发货人地址：" + order["shipperAddress"] + "<br/>")
.append("发货人电话：" + order["shipperPhone"] + "<br/>")
.append("下单时间：" + order["orderTime"] + "<br/>")
.append("发货时间：" + order["shipTime"] + "<hr/>")
.append("收货人：" + order["receiver"] + "<br/>")
.append("收获人地址：" + order['receiverAddress'] + "<br/>")
.append("收获人手机：" + order["receiverPhone"]);
 // 获取物流信息
 let logistics = order['logistics'];
 // 倒序循环
 for (var i = logistics.length - 1; i >= 0; i--) {
// 处理物流信息
$("#logistics").append('<li class="layui-timeline-item">' +
    '<i class="layui-icon layui-timeline-axis"></i>' +
    '<div class="layui-timeline-content layui-text">' +
    '<h3 class="layui-timeline-title">' +
    '（' + logistics[i].operation + '）' +
    logistics[i].operationTime + '</h3>' +
    '<p>' + logistics[i].details + '</p>' +
    '<p>操作员：' + logistics[i].operator + '&amp;nbsp;' +
    '操作员电话：' + logistics[i].phone + '&amp;nbsp;' +
    '操作地址：' + logistics[i].address + '</p></div></li>');
 }
  },
   });
    }
    // 数据表格
    layui.use('table', function () {
   var table = layui.table;
   //第一个实例
   table.render({
  elem: '#orderList',
  url: '/order/list', //数据接口
  page: true, //开启分页
  toolbar: '#toolbarDemo', // 头工具栏
  cols: [[ // 表头
 {field: 'id', title: '订单编号', sort: true, fixed: 'left'},
 {field: 'status', title: '订单状态'},
 {field: 'orderTime', title: '下单时间', sort: true},
 {field: 'shipper', title: '发货人'},
 {field: 'shipperAddress', title: '发货地址'},
 {field: 'shipperPhone', title: '发货人电话'},
 {field: 'receiver', title: '收货人', edit: 'text'},
 {field: 'receiverAddress', title: '收货地址'},
 {field: 'receiverPhone', title: '收货人电话'},
 {fixed: 'right', title: '操作', toolbar: '#barDemo'} // 行工具栏
  ]]
   });
   //工具条事件
   table.on('tool(orderTable)', function (obj) { //注：tool 是工具条事件名，test 是 table 原始容器的属性 lay-filter="对应的值"
  var data = obj.data; //获得当前行数据
  var layEvent = obj.event; //获得 lay-event 对应的值（也可以是表头的 event 参数对应的值）
  var tr = obj.tr; //获得当前行 tr 的 DOM 对象（如果有的话）
  if (layEvent === 'detail') { //查看
 //do somehing
  } else if (layEvent === 'del') { //删除
 layer.confirm('真的删除行么', function (index) {
obj.del(); //删除对应行（tr）的DOM结构，并更新缓存
layer.close(index);
//向服务端发送删除指令
$.ajax({
    url: "/order/delete",
    type: "POST",
    data: {"id": data.id},
    dataType: "JSON",
    success: function (result) {
   layer.msg(result);
    }
});
 });
  } else if (layEvent === 'edit') { //编辑
 //do something
 //同步更新缓存对应的值
 obj.update({
username: '123'
, title: 'xxx'
 });
  } else if (layEvent === 'LAYTABLE_TIPS') {
 layer.alert('Hi，头部工具栏扩展的右侧图标。');
  }
   });
    });
</script>
</body>
</html>
文章暂时更新至此，后续将推出开发SpringBoot-MongoDB完整系统
========================
https://viper3.top/885/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！本文只截取《Python数据分析与挖掘实战（第2版）》的第五章部分代码
第三方库版本——>
pandas 1.5.2
numpy 1.23.5
scikit-learn 1.1.3
keras 2.11.0
matplotlib 3.6.2
statsmodels 0.13.5
附上清华镜像使用方法：
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple XXXXXX为第三方库名称
在安装keras第三方库后进行调用时通常会出现“No module named tensorflow”，因此需要进行安装tensorflow库，本文使用的版本为2.11.0
# 载入第三方库
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier as DTC
from sklearn.tree import export_graphviz
from keras.models import Sequential
from keras.layers.core import Dense, Activation
import sklearn.metrics as mt
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_curve  #导入ROC曲线函数
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号
from statsmodels.graphics.tsaplots import plot_acf  # 自相关图
from statsmodels.graphics.tsaplots import plot_pacf
from statsmodels.tsa.stattools import adfuller as ADF  # 平稳性检测
from statsmodels.stats.diagnostic import acorr_ljungbox  # 白噪声检验
from statsmodels.tsa.arima.model import ARIMA
from sklearn.model_selection import train_test_split
P113-114
# 参数初始化
filename = '../data/sales_data.xls'
data = pd.read_excel(filename, index_col='序号')  # 导入数据
# 数据是类别标签，要将它转换为数据
# 用1来表示“好” “是” “高” 这3个属性，用-1来表示”坏“ ”否“ ”低“
data[data == '好'] = 1
data[data == '是'] = 1
data[data == '高'] = 1
data[data != 1] = -1
x = data.iloc[:, :3].values.astype(int)
y = data.iloc[:, 3].values.astype(int)
dtc = DTC(criterion='entropy')  # 建立决策树模型，基于信息熵
dtc.fit(x, y)  # 训练模型
# 导入相关函数，可视化决策树
# 导出的结果是一个dot文件，需要安装Graphviz才能将它转换为pdf或png等格式
x = pd.DataFrame(x)
with open("../tmp/tree.dot", "w") as f:
    f = export_graphviz(dtc, feature_names=x.columns, out_file=f)
P119-120
# 参数初始化
inputfile = '../data/sales_data.xls'
data = pd.read_excel(inputfile, index_col='序号')  # 导入数据
# 数据是类别标签，要将它转换为数据
# 用1来表示“好” “是” “高” 这3个属性，用-1来表示”坏“ ”否“ ”低“
data[data == '好'] = 1
data[data == '是'] = 1
data[data == '高'] = 1
data[data != 1] = 0
x = data.iloc[:, :3].values.astype(int)
y = data.iloc[:, 3].values.astype(int)
model = Sequential()
model.add(Dense(input_dim=3, units=10))
model.add(Dense(input_dim=10, units=1))
# 由于0-1输出，用sigmoid函数作为激活函数
model.add(Activation('sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam')
# 编译模型。由于我们做的是二元分类，所以我们指定损失函数为binary_crossentropy，以及模式为binary
# 另外常见的损失函数还有mean_squared_error、categorical_crossentropy等
# 对于求解方法，我们指定用adam，此外还有sgd、rmsprop等可选
# 训练模型，学习一千次
model.fit(x, y, epochs=1000, batch_size=10)
# 分类预测 
"""由于keras第三方库版本过高，因此predict_classes方法已被弃用，使用predict方法替代"""
"""yp = model.predict(x).reshape(len(y))"""
yp = np.around((model.predict(x).reshape(len(y))), 0).astype(int)
from cm_plot import *  # 导入自行编写的混淆矩阵可视化函数
cm_plot(y, yp).show()  # 显示混淆矩阵可视化结果
ppt91
train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)
dtc = DTC()  #(criterion='entropy')  # 建立决策树模型，基于信息熵
dtc.fit(train_x, train_y)  # 训练模型
yp = dtc.predict(test_x)
acc = mt.accuracy_score(test_y, yp)  #正确分类的得分
acc_num = mt.accuracy_score(test_y, yp, normalize=False)  #正确分类的样本数量
prs = mt.precision_score(test_y, yp)
rcl = mt.recall_score(test_y, yp)
ffs = mt.f1_score(test_y, yp)  # F1指数
print("正确分类的得分为：", acc)
print("正确分类的样本数量为：", acc_num)
print("精确分类的得分为：", prs)
print("召回的得分为：", rcl)
print("F1指数为：", ffs)
ppt94
y_true = [2, 0, 2, 2, 0, 1]
y_pred = [0, 0, 2, 2, 0, 2]
kappa_value = cohen_kappa_score(y_true, y_pred)
print("kappa值为%f" % kappa_value)
ppt98
fpr, tpr, thresholds = roc_curve(y, dtc.predict(x))
# sklearn.metrics.roc_curve(y_true,y_score,pos_label=None,sample_weight=None,drop_intermediate=True)
# y_true: 真实标签矩阵;y_score:模型的预测结果矩阵;pos_label: 标签中认定为正的label个数;
# sample_weight:采样权重;drop_intermediate:可选择去掉一些对于ROC性能不利的阈值，使得得到的曲线有更好的表现性能
plt.plot(fpr, tpr, linewidth=2, label='roc curve', color='green')  #作出ROC曲线
plt.xlabel('False Positive Rate')  #坐标轴标签
plt.ylabel('True Positive Rate')  #坐标轴标签
plt.ylim(0, 1.05)  #边界范围
plt.xlim(0, 1.05)  #边界范围
# plt.legend(loc='best',frameon=True) #图例
plt.legend(loc=0)
# 0: ‘best'  1: ‘upper right'  2: ‘upper left'  3: ‘lower left'  4: ‘lower right'  5: ‘right'
# 6: ‘center left'  7: ‘center right'  8: ‘lower center'  9: ‘upper center'  10: ‘center'
plt.show()  # 显示作图结果
P154-155 PPT62
# 参数初始化
discfile = '../data/arima_data.xls'
forecastnum = 5
# 读取数据，指定日期列为指标，pandas自动将“日期”列识别为Datetime格式
data = pd.read_excel(discfile, index_col=u'日期')
# 时序图
data.plot()
plt.show()
# 自相关图
plot_acf(data).show()
# 平稳性检测
print(u'原始序列的ADF检验结果为：', ADF(data[u'销量']))
# 返回值依次为adf、pvalue、usedlag、nobs、critical values、icbest、regresults、resstore
# 差分后的结果
D_data = data.diff().dropna()
D_data.columns = [u'销量差分']
D_data.plot()  # 时序图
plt.show()
plot_acf(D_data).show()  # 自相关图
plot_pacf(D_data).show()  # 偏自相关图
print(u'差分序列的ADF检验结果为：\n', ADF(D_data[u'销量差分']))  # 平稳性检测
# 白噪声检验
print(u'差分序列的白噪声检验结果为：\n', acorr_ljungbox(D_data, lags=1))  # 返回统计量和p值
# 定阶
data[u'销量'] = data[u'销量'].astype(float)
pmax = int(len(D_data) / 10)  # 一般阶数不超过length/10
qmax = int(len(D_data) / 10)  # 一般阶数不超过length/10
bic_matrix = []  # BIC矩阵
for p in range(pmax + 1):
    tmp = []
    for q in range(qmax + 1):
   try:  # 存在部分报错，所以用try来跳过报错。
  """建立ARIMA模型时，由于第三方库版本问题，需使用order参数"""
  tmp.append(ARIMA(data, order=(p, 1, q)).fit().bic)
   except:
 tmp.append(None)
    bic_matrix.append(tmp)
bic_matrix = pd.DataFrame(bic_matrix)  # 从中可以找出最小值
p, q = bic_matrix.stack().idxmin()  # 先用stack展平，然后用idxmin找出最小值位置。
print(u'BIC最小的p值和q值为：%s、%s' % (p, q))
"""建立ARIMA模型时，由于第三方库版本问题，需使用order参数"""
model = ARIMA(data, order=(p, 1, q)).fit()  # 建立ARIMA(0, 1, 1)模型
"""由于statsmodels版本过高，因此summary2方法已被弃用，使用summary方法替代，输出模型报告"""
print('模型报告为：\n', model.summary())
print('预测未来5天，其预测结果、标准误差、置信区间如下：\n', model.forecast(5))
========================
https://viper3.top/134/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！.m3u8文件：点击获取
import re
import requests
import os
# 获得.ts文件的URL，此处返回的是一个数组。
def getTsUrl(file):
    lines = file.readlines()  # 读取每一行的内容
    ts_url = []  # 创建一个空列表，准备存储.ts文件的URL
    for line in lines:  # 遍历m3u8文件中的每一行
   if re.match('https://.*?\n', line):  # 使用正则匹配.ts文件的URL
  line = line.strip('\n')  # 删除尾随的换行符
  ts_url.append(line)  # 增添到数组中
    return ts_url
# 下载.ts文件
def dl(tsUrls):
    response = ""  # 创造dl方法中的全局变量
    headers = {
   "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) "
  "Chrome/97.0.4692.99 Safari/537.36 Edg/97.0.1072.69 "
    }
    i = 1  # 为命名.ts文件做准备，同时可以作为计数器使用
    try:
   for tsUrl in tsUrls:
  response = requests.get(tsUrl, headers=headers)
  path = "./ts/{:0>4}.ts".format(str(i))  # .ts文件的储存路径及名字，此处采用的右对齐，长度4（所需长度根据.ts文件的数量来决定），填充字母为'0'。 例如：1为0001
  f = open(path, "wb")  # 以二进制(bytes)的形式写入
  f.write(response.content)  # .content为响应内容的二进制(bytes)形式
  f.close()
  print("已经下载了" + str(i) + "个文件，总共有" + str(len(tsUrls)) + "个文件，完成度：{:.2f}%".format(i * 100 / len(tsUrls)))
  i += 1
    except:
   if response != "<Response [200]>":
  print("当请求到第" + str(i) + "个.ts文件链接时，请求出现错误!")
  print(response)
   else:
  print("当下载到第" + str(i) + "个.ts文件时，下载出错!")
# 将所有的.ts文件名写入一个.txt文件中(在txt文件中以  file '文件名的二进制格式.ts'  的格式显示)
def writeIntoTxt():
    file_Path = "./ts/"  # .ts文件的储存路径
    file_list = sorted(os.listdir(file_Path))  # os.listdir(____)获得某一路径下的所有文件的文件名，sorted()降序排序
    f = open(file_Path + "file_list.txt", "w+")  # .txt文件要和.ts文件在同一路径下
    for file in file_list:
   f.write("file '{}'\n".format(file))  # 写入.txt文件中，格式为  file '文件名的二进制格式.ts'  为ffmpeg处理做准备
    f.close()
# 打开m3u8文件，为getTsUrl提供参数
file_m3u8 = open(file='007.m3u8', mode='r', encoding='UTF-8')
# 调用getTsUrl()方法，从m3u8文件中获得.ts文件链接并存入数组
ts_list = getTsUrl(file_m3u8)
# 调用dl()方法，遍历getTsUrl()方法得到的数组，将.ts文件下载到path路径中
dl(ts_list)
# 调用writeIntoTxt()方法，将所有的.ts文件名写入一个.txt文件中
writeIntoTxt()
# ---------- 最后一步，在cmd命令行中操作 ------------
# ------------- 进入ts文件所在的目录 ---------------
# ------------ cd （ts文件所在的目录） --------------
# ----------- 执行 ffmpeg 合并转换命令 ------------
# ffmpeg -f concat -i 文件名.txt -c copy 自定义命名.mp4
# -------或者执行 copy /b *.ts 自定义名.mp4--------
# 007：无暇赴死(原声版) No Time to Die
print("{:-^30}".format("完成"))
========================
https://viper3.top/791/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！1. 进入申请界面
打开JetBrains的官网：https://www.jetbrains.com/
电子邮箱地址需要填写学校认证的邮箱，一般为：学号+学校域名。
申请免费产品后看到下图后，登录学校邮箱后查看收件箱，即可看到激活邮件，点击邮件中的该链接。
到这里提示你离成功差一步之遥，点击 Get started to use。
会直接跳转到类似于用户须知的页面，你需要将那个进度条拉到最底下之后才能点accept。
到这里你就成功了。
下一步即可登录（未注册的先注册账户）jetbrains账户，使用jetbrains全家桶专业版！
如下图：
========================
https://viper3.top/137/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！示例使用 豆瓣北京-影讯 页面内容。
import time
import threading
import requests
from bs4 import BeautifulSoup
# 正常爬取
start_time = time.time()
print("任务开始")
result = []
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.66 Safari/537.36 Edg/103.0.1264.44"
}
url = "https://movie.douban.com/cinema/later/beijing/"
resp = requests.get(url, headers=headers)
page = resp.text
soup = BeautifulSoup(page, 'html.parser')
url_list = soup.select("#showing-soon > div > div > h3 > a")
urls = []
for i in url_list:
    urls.append(i.get("href"))
for url2 in urls:
    resp2 = requests.get(url2, headers=headers)
    page2 = resp2.text
    soup2 = BeautifulSoup(page2, 'html.parser')
    head = soup2.find("head")
    title = head .find("title").get_text().strip()
    result.append(title)
end_time = time.time()
total_time = end_time - start_time
print("任务结束，总耗时为：{}".format(total_time))
for i in result:
    print(i,end="   ")
输出结果： 任务开始任务结束，总耗时为：21.05104684829712神探大战 (豆瓣) 隐入尘烟 (豆瓣) 海底小纵队：洞穴大冒险 (豆瓣) 外太空的莫扎特 (豆瓣) 龙女孩 (豆瓣) 冲出地球 (豆瓣) 二郎神之深海蛟龙 (豆瓣) 开心超人之英雄的心 (豆瓣) 阳光照耀塔什库尔干 (豆瓣) 七人乐队 (豆瓣) 疯了！桂宝之三星夺宝 (豆瓣) 漫长的告白 (豆瓣) 念念相忘 (豆瓣) 遇见你 (豆瓣) 我们的样子像极了爱情 (豆瓣) 她的爱情 (豆瓣) 世界上最爱我的人 (豆瓣) 断网 (豆瓣) 重回地球 (豆瓣) 撼沙 (豆瓣) 红孩儿之初生牛犊 (豆瓣) 小美人鱼之大海怪传说 (豆瓣) 新灰姑娘2 (豆瓣)
# 多线程爬取
result = []
def get(urls, name):
    # print("进程\033[1;33m{}\033[0m开始".format(name))
    global result
    headers = {
   "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.66 Safari/537.36 Edg/103.0.1264.44"
    }
    for url in urls:
   resp = requests.get(url, headers=headers)
   page = resp.text
   soup = BeautifulSoup(page, 'html.parser')
   head = soup.find("head")
   title = head .find("title").get_text().strip()
   result.append(title)
    # print("进程\033[1;33m{}\033[0m结束".format(name))
def main():
    print("主任务开始")
    start_time = time.time()
    headers = {
   "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.66 Safari/537.36 Edg/103.0.1264.44"
    }
    url = "https://movie.douban.com/cinema/later/beijing/"
    resp = requests.get(url, headers=headers)
    page = resp.text
    soup = BeautifulSoup(page, 'html.parser')
    url_list = soup.select("#showing-soon > div > div > h3 > a")
    urls = []
    for i in url_list:
   urls.append(i.get("href"))
    t1 = threading.Thread(target=get, args=(urls[0:4],"一"))
    t2 = threading.Thread(target=get, args=(urls[4:8],"二"))
    t3 = threading.Thread(target=get, args=(urls[8:12],"三"))
    t4 = threading.Thread(target=get, args=(urls[12:16],"四"))
    t5 = threading.Thread(target=get, args=(urls[16:20],"五"))
    t6 = threading.Thread(target=get, args=(urls[20:],"六"))
    t1.start()
    t2.start()
    t3.start()
    t4.start()
    t5.start()
    t6.start()
    t1.join()
    t2.join()
    t3.join()
    t4.join()
    t5.join()
    t6.join()
    end_time = time.time()
    total_time = end_time - start_time
    print("主任务结束，总耗时为：{}".format(total_time))
    for i in result:
   print(i,end="   ")
if __name__ == "__main__":
    main()
输出结果： 主任务开始主任务结束，总耗时为：4.847523927688599阳光照耀塔什库尔干 (豆瓣) 龙女孩 (豆瓣) 红孩儿之初生牛犊 (豆瓣) 神探大战 (豆瓣) 念念相忘 (豆瓣) 世界上最爱我的人 (豆瓣) 七人乐队 (豆瓣) 小美人鱼之大海怪传说 (豆瓣) 隐入尘烟 (豆瓣) 断网 (豆瓣) 遇见你 (豆瓣) 冲出地球 (豆瓣) 疯了！桂宝之三星夺宝 (豆瓣) 新灰姑娘2 (豆瓣) 海底小纵队：洞穴大冒险 (豆瓣) 我们的样子像极了爱情 (豆瓣) 二郎神之深海蛟龙 (豆瓣) 重回地球 (豆瓣) 漫长的告白 (豆瓣) 外太空的莫扎特 (豆瓣) 撼沙 (豆瓣) 开心超人之英雄的心 (豆瓣) 她的爱情 (豆瓣)正常爬取所花费的时间是多线程爬取的四倍。 
========================
https://viper3.top/917/
❗❗❗本文最后更新于 66 天前，其中的信息可能已经过时；如有错误请在文章下方评论✅，欢迎纠错🥰！
一、不蒜子简介
“静态网站建站现在有很多快速的技术和平台，但静态是优点也有缺点，由于是静态的，一些动态的内容如评论、计数等等模块就需要借助外来平台，评论有“多说”，计数有“不蒜”！（多说即将关闭，不蒜子还活着涅，这是程序员对程序员的承诺。）“不蒜子”与百度统计谷歌分析等有区别：“不蒜子”可直接将访问次数显示在您在网页上（也可不显示）；对于已经上线一段时间的网站，“不蒜子”允许您初始化首次数据。。普通用户只需两步走：一行脚本+一行标签，搞定一切。追求极致的用户可以进行任意DIY。”
二、不蒜子的计数原理
在引入的JS(JavaScript)脚本中，会把当前页面url（或某种唯一标识）注册到其第三方服务器，服务器上保存着url与对应的计数值，点击页面后通过JS更新服务器上的计数值，并在页面初始化时在本地标签加载、显示计数值。
三、如何使用
在网页需要引用计数功能的地方先引入不蒜子的js
<!-- 引入不蒜子计数 -->
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
为了美观，我们再引入旋转花瓣加载特效”fa fa-spinner fa-spin”总访问量计数算法：pv方式，单个用户连续点击n篇文章，记录n次访问量。总访客数计数算法：uv方式，单个用户连续点击n篇文章，只记录1次访客数。
浏览量：<span id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></span>
访客数：<span id="busuanzi_value_site_uv"><i class="fa fa-spinner fa-spin"></i></span>
注：美化及其他嵌入的改动，其实只要内层的span就可以，然后用css美化或者做嵌入
四、效果图
加载中：
加载完毕：
========================
